{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anovaes2002/active_learning/blob/main/Alexsander_Active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Como rodei inicialmente no Colab, deixei a instalação no codigo\n",
        "!pip install tensorflow-datasets\n",
        "!pip install tfds-nightly\n",
        "!pip install --upgrade tensorflow-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvPtHnIHSuWP",
        "outputId": "8b77787a-fa82-4afa-f115-bd1f5954c35f"
      },
      "id": "wvPtHnIHSuWP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (4.6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (4.64.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.23.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.1.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.11.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tensorflow-datasets) (3.10.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tensorflow-datasets) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.57.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.8/dist-packages (4.7.0.dev202212010045)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (0.1.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (4.64.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (1.11.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (5.10.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (1.21.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (2.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (3.19.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tfds-nightly) (0.10.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tfds-nightly) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tfds-nightly) (3.10.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tfds-nightly) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tfds-nightly) (1.57.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-hub) (3.19.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b06e0c37",
      "metadata": {
        "id": "b06e0c37"
      },
      "outputs": [],
      "source": [
        "#importando bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import re\n",
        "import string\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos o conjunto de dados de avaliações do IMDB para nossos experimentos Este conjunto de dados tem 50.000 revisões no total, incluindo divisões de treinamento e teste. Vamos mesclar essas divisões e amostrar nossos próprios conjuntos de treinamento, validação e teste balanceados."
      ],
      "metadata": {
        "id": "9F00NOw7mq29"
      },
      "id": "9F00NOw7mq29"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f123a4e7",
      "metadata": {
        "id": "f123a4e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fb16c5-d63f-4ce9-b019-aedc7d7f1420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n",
            "Total examples: 50000\n"
          ]
        }
      ],
      "source": [
        "#Importando dataset imdb\n",
        "dataset = tfds.load(\n",
        "    \"imdb_reviews\",\n",
        "    split=\"train + test\",\n",
        "    as_supervised=True,\n",
        "    batch_size=-1,\n",
        "    shuffle_files=False,\n",
        ")\n",
        "reviews, labels = tfds.as_numpy(dataset)\n",
        "\n",
        "print(\"Total examples:\", reviews.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividindo o dataset\n",
        "val_split   = 2500\n",
        "test_split  = 2500\n",
        "train_split = 7500\n",
        "\n",
        "# Separando as amostras negativas e positivas para estratificação manual\n",
        "x_positives, y_positives = reviews[labels == 1], labels[labels == 1]\n",
        "x_negatives, y_negatives = reviews[labels == 0], labels[labels == 0]\n",
        "\n",
        "# Criação de divisões de treinamento, validação e teste\n",
        "x_val, y_val = (\n",
        "    tf.concat((x_positives[:val_split], x_negatives[:val_split]), 0),\n",
        "    tf.concat((y_positives[:val_split], y_negatives[:val_split]), 0),\n",
        ")\n",
        "x_test, y_test = (\n",
        "    tf.concat(\n",
        "        (\n",
        "            x_positives[val_split : val_split + test_split],\n",
        "            x_negatives[val_split : val_split + test_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        "    tf.concat(\n",
        "        (\n",
        "            y_positives[val_split : val_split + test_split],\n",
        "            y_negatives[val_split : val_split + test_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        ")\n",
        "x_train, y_train = (\n",
        "    tf.concat(\n",
        "        (\n",
        "            x_positives[val_split + test_split : val_split + test_split + train_split],\n",
        "            x_negatives[val_split + test_split : val_split + test_split + train_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        "    tf.concat(\n",
        "        (\n",
        "            y_positives[val_split + test_split : val_split + test_split + train_split],\n",
        "            y_negatives[val_split + test_split : val_split + test_split + train_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# O conjunto restante de amostras é armazenado separadamente. Estes são rotulados apenas como e quando necessário\n",
        "x_pool_positives, y_pool_positives = (\n",
        "    x_positives[val_split + test_split + train_split :],\n",
        "    y_positives[val_split + test_split + train_split :],\n",
        ")\n",
        "x_pool_negatives, y_pool_negatives = (\n",
        "    x_negatives[val_split + test_split + train_split :],\n",
        "    y_negatives[val_split + test_split + train_split :],\n",
        ")\n",
        "\n",
        "# Criação de conjuntos de dados TF para pré-busca e paralelização mais rápidas\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset   = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset  = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "pool_negatives = tf.data.Dataset.from_tensor_slices((x_pool_negatives, y_pool_negatives))\n",
        "pool_positives = tf.data.Dataset.from_tensor_slices((x_pool_positives, y_pool_positives))\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Testing set size: {len(test_dataset)}\")\n",
        "print(f\"Unlabeled negative pool: {len(pool_negatives)}\")\n",
        "print(f\"Unlabeled positive pool: {len(pool_positives)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi5B-AjgUFF_",
        "outputId": "a0fd440f-f300-4175-d42b-b793283addaf"
      },
      "id": "Vi5B-AjgUFF_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 15000\n",
            "Validation set size: 5000\n",
            "Testing set size: 5000\n",
            "Unlabeled negative pool: 12500\n",
            "Unlabeled positive pool: 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Como estamos trabalhando com dados de texto, precisaremos codificar as sequências de texto como vetores que serão passados ​​por uma Embeddingcamada. \n",
        "#Para tornar esse processo de tokenização mais rápido, usamos a map()função com sua funcionalidade de paralelização.\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase     = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "vectorizer = layers.TextVectorization(3000, standardize=custom_standardization, output_sequence_length=150)\n",
        "\n",
        "# Adaptando o dataset\n",
        "vectorizer.adapt(train_dataset.map(lambda x, y: x, num_parallel_calls=tf.data.AUTOTUNE).batch(256))\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "    text = vectorizer(text)\n",
        "    return text, label\n",
        "\n",
        "def batch_dataset(dataset):\n",
        "    ds = dataset.batch(100)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "JqDfO1ukUePC"
      },
      "id": "JqDfO1ukUePC",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "715ccd1b",
      "metadata": {
        "id": "715ccd1b"
      },
      "outputs": [],
      "source": [
        "#Fechando os datasets de treinamento, validação, teste e pool\n",
        "train_dataset  = train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset    = val_dataset.batch(256).map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset   = test_dataset.batch(256).map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "pool_negatives = pool_negatives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "pool_positives = pool_positives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c32d3b6",
      "metadata": {
        "id": "8c32d3b6"
      },
      "outputs": [],
      "source": [
        "#Épocas de treinamento\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d73c14fe",
      "metadata": {
        "id": "d73c14fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fd0bfb-2847-458b-d836-a6d67639f26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 128)          384000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 150, 64)          41216     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                1300      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 426,537\n",
            "Trainable params: 426,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Definindo o modelo\n",
        "model = keras.models.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(150,)),\n",
        "        layers.Embedding(input_dim=3000, output_dim=128),\n",
        "        layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n",
        "        layers.GlobalMaxPool1D(),\n",
        "        layers.Dense(20, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "efdfb7b4",
      "metadata": {
        "id": "efdfb7b4"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss      = \"binary_crossentropy\",\n",
        "    optimizer = \"rmsprop\",\n",
        "    metrics   = [keras.metrics.BinaryAccuracy(),],)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mostrar a eficácia do Active Learning, vamos primeiro treinar o modelo em todo o conjunto de dados contendo 40.000 amostras rotuladas. Este modelo será utilizado para comparação posteriormente."
      ],
      "metadata": {
        "id": "FHH1YUKMoPZf"
      },
      "id": "FHH1YUKMoPZf"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e1e297ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1e297ba",
        "outputId": "d963e0d9-3a96-4a43-8bf4-5a2be6d6926d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "157/157 [==============================] - 14s 29ms/step - loss: 0.5010 - binary_accuracy: 0.8166 - val_loss: 1.9796 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.4101 - binary_accuracy: 0.8842 - val_loss: 2.9691 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.3247 - binary_accuracy: 0.9304 - val_loss: 3.4953 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2722 - binary_accuracy: 0.9467 - val_loss: 3.9151 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2674 - binary_accuracy: 0.9531 - val_loss: 4.0934 - val_binary_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2573 - binary_accuracy: 0.9569 - val_loss: 4.2056 - val_binary_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2439 - binary_accuracy: 0.9604 - val_loss: 4.4870 - val_binary_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2367 - binary_accuracy: 0.9646 - val_loss: 4.5846 - val_binary_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2419 - binary_accuracy: 0.9653 - val_loss: 4.5981 - val_binary_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2381 - binary_accuracy: 0.9670 - val_loss: 4.4997 - val_binary_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2230 - binary_accuracy: 0.9711 - val_loss: 4.6530 - val_binary_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2211 - binary_accuracy: 0.9743 - val_loss: 4.7278 - val_binary_accuracy: 0.5006\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2234 - binary_accuracy: 0.9747 - val_loss: 4.7609 - val_binary_accuracy: 0.5008\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2284 - binary_accuracy: 0.9745 - val_loss: 4.8164 - val_binary_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2181 - binary_accuracy: 0.9744 - val_loss: 4.6812 - val_binary_accuracy: 0.5014\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2088 - binary_accuracy: 0.9759 - val_loss: 4.8820 - val_binary_accuracy: 0.5004\n",
            "Epoch 17/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2118 - binary_accuracy: 0.9760 - val_loss: 4.8337 - val_binary_accuracy: 0.5004\n",
            "Epoch 18/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2055 - binary_accuracy: 0.9764 - val_loss: 5.0044 - val_binary_accuracy: 0.5004\n",
            "Epoch 19/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2065 - binary_accuracy: 0.9740 - val_loss: 5.2537 - val_binary_accuracy: 0.5004\n",
            "Epoch 20/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.2045 - binary_accuracy: 0.9762 - val_loss: 4.8578 - val_binary_accuracy: 0.5034\n",
            "Epoch 21/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1843 - binary_accuracy: 0.9777 - val_loss: 4.8557 - val_binary_accuracy: 0.5030\n",
            "Epoch 22/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1895 - binary_accuracy: 0.9778 - val_loss: 4.7879 - val_binary_accuracy: 0.5070\n",
            "Epoch 23/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1867 - binary_accuracy: 0.9773 - val_loss: 5.1571 - val_binary_accuracy: 0.5026\n",
            "Epoch 24/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1882 - binary_accuracy: 0.9771 - val_loss: 5.0524 - val_binary_accuracy: 0.5056\n",
            "Epoch 25/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1853 - binary_accuracy: 0.9771 - val_loss: 5.2109 - val_binary_accuracy: 0.5024\n",
            "Epoch 26/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1832 - binary_accuracy: 0.9779 - val_loss: 5.2918 - val_binary_accuracy: 0.5024\n",
            "Epoch 27/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.1873 - binary_accuracy: 0.9777 - val_loss: 5.0573 - val_binary_accuracy: 0.5052\n",
            "Epoch 28/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1761 - binary_accuracy: 0.9791 - val_loss: 5.0390 - val_binary_accuracy: 0.5054\n",
            "Epoch 29/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1975 - binary_accuracy: 0.9741 - val_loss: 4.9291 - val_binary_accuracy: 0.5052\n",
            "Epoch 30/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1672 - binary_accuracy: 0.9785 - val_loss: 5.0722 - val_binary_accuracy: 0.5060\n",
            "Epoch 31/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.1683 - binary_accuracy: 0.9793 - val_loss: 5.2449 - val_binary_accuracy: 0.5082\n",
            "Epoch 32/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1699 - binary_accuracy: 0.9799 - val_loss: 5.1954 - val_binary_accuracy: 0.5088\n",
            "Epoch 33/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1892 - binary_accuracy: 0.9760 - val_loss: 5.5756 - val_binary_accuracy: 0.5048\n",
            "Epoch 34/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1666 - binary_accuracy: 0.9800 - val_loss: 5.4350 - val_binary_accuracy: 0.5056\n",
            "Epoch 35/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1713 - binary_accuracy: 0.9797 - val_loss: 5.7662 - val_binary_accuracy: 0.5088\n",
            "Epoch 36/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1648 - binary_accuracy: 0.9804 - val_loss: 5.4524 - val_binary_accuracy: 0.5092\n",
            "Epoch 37/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1631 - binary_accuracy: 0.9797 - val_loss: 5.8656 - val_binary_accuracy: 0.5084\n",
            "Epoch 38/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1748 - binary_accuracy: 0.9794 - val_loss: 5.7917 - val_binary_accuracy: 0.5078\n",
            "Epoch 39/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1621 - binary_accuracy: 0.9798 - val_loss: 6.2413 - val_binary_accuracy: 0.5098\n",
            "Epoch 40/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1639 - binary_accuracy: 0.9805 - val_loss: 5.8709 - val_binary_accuracy: 0.5116\n",
            "Epoch 41/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1522 - binary_accuracy: 0.9817 - val_loss: 6.4262 - val_binary_accuracy: 0.5116\n",
            "Epoch 42/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1529 - binary_accuracy: 0.9820 - val_loss: 6.5237 - val_binary_accuracy: 0.5088\n",
            "Epoch 43/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1676 - binary_accuracy: 0.9786 - val_loss: 6.2123 - val_binary_accuracy: 0.5040\n",
            "Epoch 44/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1660 - binary_accuracy: 0.9793 - val_loss: 7.1066 - val_binary_accuracy: 0.5076\n",
            "Epoch 45/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1661 - binary_accuracy: 0.9812 - val_loss: 6.6188 - val_binary_accuracy: 0.5138\n",
            "Epoch 46/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1398 - binary_accuracy: 0.9830 - val_loss: 6.5017 - val_binary_accuracy: 0.5114\n",
            "Epoch 47/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.1399 - binary_accuracy: 0.9834 - val_loss: 6.3876 - val_binary_accuracy: 0.5152\n",
            "Epoch 48/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1315 - binary_accuracy: 0.9841 - val_loss: 6.4567 - val_binary_accuracy: 0.5174\n",
            "Epoch 49/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1543 - binary_accuracy: 0.9811 - val_loss: 6.4209 - val_binary_accuracy: 0.5158\n",
            "Epoch 50/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.1339 - binary_accuracy: 0.9836 - val_loss: 6.5947 - val_binary_accuracy: 0.5158\n",
            "Epoch 51/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1283 - binary_accuracy: 0.9847 - val_loss: 6.6569 - val_binary_accuracy: 0.5102\n",
            "Epoch 52/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1307 - binary_accuracy: 0.9832 - val_loss: 6.5964 - val_binary_accuracy: 0.5158\n",
            "Epoch 53/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1211 - binary_accuracy: 0.9857 - val_loss: 6.8739 - val_binary_accuracy: 0.5138\n",
            "Epoch 54/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1239 - binary_accuracy: 0.9855 - val_loss: 6.9078 - val_binary_accuracy: 0.5116\n",
            "Epoch 55/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1254 - binary_accuracy: 0.9849 - val_loss: 7.0601 - val_binary_accuracy: 0.5086\n",
            "Epoch 56/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1174 - binary_accuracy: 0.9857 - val_loss: 7.2867 - val_binary_accuracy: 0.5086\n",
            "Epoch 57/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1162 - binary_accuracy: 0.9857 - val_loss: 6.8987 - val_binary_accuracy: 0.5170\n",
            "Epoch 58/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1217 - binary_accuracy: 0.9849 - val_loss: 6.8369 - val_binary_accuracy: 0.5088\n",
            "Epoch 59/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1161 - binary_accuracy: 0.9851 - val_loss: 7.2477 - val_binary_accuracy: 0.5072\n",
            "Epoch 60/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1642 - binary_accuracy: 0.9793 - val_loss: 7.0071 - val_binary_accuracy: 0.5162\n",
            "Epoch 61/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1213 - binary_accuracy: 0.9842 - val_loss: 6.9243 - val_binary_accuracy: 0.5078\n",
            "Epoch 62/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.1250 - binary_accuracy: 0.9839 - val_loss: 6.9367 - val_binary_accuracy: 0.5174\n",
            "Epoch 63/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1157 - binary_accuracy: 0.9852 - val_loss: 6.7430 - val_binary_accuracy: 0.5188\n",
            "Epoch 64/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1051 - binary_accuracy: 0.9862 - val_loss: 7.5961 - val_binary_accuracy: 0.5104\n",
            "Epoch 65/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1159 - binary_accuracy: 0.9856 - val_loss: 6.9766 - val_binary_accuracy: 0.5174\n",
            "Epoch 66/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1203 - binary_accuracy: 0.9842 - val_loss: 6.8845 - val_binary_accuracy: 0.5202\n",
            "Epoch 67/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0906 - binary_accuracy: 0.9883 - val_loss: 7.0972 - val_binary_accuracy: 0.5170\n",
            "Epoch 68/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0993 - binary_accuracy: 0.9868 - val_loss: 7.2334 - val_binary_accuracy: 0.5124\n",
            "Epoch 69/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0954 - binary_accuracy: 0.9874 - val_loss: 7.1109 - val_binary_accuracy: 0.5198\n",
            "Epoch 70/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1054 - binary_accuracy: 0.9872 - val_loss: 6.8745 - val_binary_accuracy: 0.5196\n",
            "Epoch 71/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0893 - binary_accuracy: 0.9881 - val_loss: 6.9357 - val_binary_accuracy: 0.5206\n",
            "Epoch 72/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0922 - binary_accuracy: 0.9879 - val_loss: 6.9823 - val_binary_accuracy: 0.5182\n",
            "Epoch 73/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.1115 - binary_accuracy: 0.9844 - val_loss: 6.6925 - val_binary_accuracy: 0.5194\n",
            "Epoch 74/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0845 - binary_accuracy: 0.9886 - val_loss: 7.1630 - val_binary_accuracy: 0.5168\n",
            "Epoch 75/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0790 - binary_accuracy: 0.9898 - val_loss: 7.0765 - val_binary_accuracy: 0.5180\n",
            "Epoch 76/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0856 - binary_accuracy: 0.9893 - val_loss: 7.1222 - val_binary_accuracy: 0.5110\n",
            "Epoch 77/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0796 - binary_accuracy: 0.9886 - val_loss: 7.4146 - val_binary_accuracy: 0.5150\n",
            "Epoch 78/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.0956 - binary_accuracy: 0.9883 - val_loss: 7.2548 - val_binary_accuracy: 0.5144\n",
            "Epoch 79/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0802 - binary_accuracy: 0.9894 - val_loss: 6.9957 - val_binary_accuracy: 0.5186\n",
            "Epoch 80/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0748 - binary_accuracy: 0.9906 - val_loss: 7.1496 - val_binary_accuracy: 0.5142\n",
            "Epoch 81/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0825 - binary_accuracy: 0.9881 - val_loss: 7.2235 - val_binary_accuracy: 0.5120\n",
            "Epoch 82/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0779 - binary_accuracy: 0.9893 - val_loss: 7.1621 - val_binary_accuracy: 0.5168\n",
            "Epoch 83/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0934 - binary_accuracy: 0.9887 - val_loss: 7.4358 - val_binary_accuracy: 0.5162\n",
            "Epoch 84/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0993 - binary_accuracy: 0.9861 - val_loss: 6.3841 - val_binary_accuracy: 0.5276\n",
            "Epoch 85/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.0848 - binary_accuracy: 0.9876 - val_loss: 6.3044 - val_binary_accuracy: 0.5250\n",
            "Epoch 86/100\n",
            "157/157 [==============================] - 4s 25ms/step - loss: 0.0658 - binary_accuracy: 0.9904 - val_loss: 6.7300 - val_binary_accuracy: 0.5208\n",
            "Epoch 87/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0596 - binary_accuracy: 0.9911 - val_loss: 6.7095 - val_binary_accuracy: 0.5238\n",
            "Epoch 88/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0698 - binary_accuracy: 0.9896 - val_loss: 6.8023 - val_binary_accuracy: 0.5228\n",
            "Epoch 89/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0572 - binary_accuracy: 0.9915 - val_loss: 6.8125 - val_binary_accuracy: 0.5270\n",
            "Epoch 90/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0613 - binary_accuracy: 0.9903 - val_loss: 6.7792 - val_binary_accuracy: 0.5252\n",
            "Epoch 91/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0638 - binary_accuracy: 0.9909 - val_loss: 6.6798 - val_binary_accuracy: 0.5268\n",
            "Epoch 92/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0484 - binary_accuracy: 0.9934 - val_loss: 7.0547 - val_binary_accuracy: 0.5260\n",
            "Epoch 93/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0491 - binary_accuracy: 0.9918 - val_loss: 7.0747 - val_binary_accuracy: 0.5272\n",
            "Epoch 94/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0548 - binary_accuracy: 0.9916 - val_loss: 6.7853 - val_binary_accuracy: 0.5260\n",
            "Epoch 95/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0503 - binary_accuracy: 0.9918 - val_loss: 6.8875 - val_binary_accuracy: 0.5258\n",
            "Epoch 96/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0525 - binary_accuracy: 0.9929 - val_loss: 6.8869 - val_binary_accuracy: 0.5244\n",
            "Epoch 97/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0581 - binary_accuracy: 0.9914 - val_loss: 6.3303 - val_binary_accuracy: 0.5420\n",
            "Epoch 98/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0715 - binary_accuracy: 0.9877 - val_loss: 6.7833 - val_binary_accuracy: 0.5264\n",
            "Epoch 99/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0500 - binary_accuracy: 0.9918 - val_loss: 7.0069 - val_binary_accuracy: 0.5270\n",
            "Epoch 100/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 0.0453 - binary_accuracy: 0.9923 - val_loss: 6.7025 - val_binary_accuracy: 0.5330\n"
          ]
        }
      ],
      "source": [
        "history1  = model.fit(\n",
        "    train_dataset.batch(256)\n",
        "    .concatenate(pool_positives.batch(256))\n",
        "    .concatenate(pool_negatives.batch(256)),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d7f025d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d7f025d",
        "outputId": "9fd823b1-c826-473b-d50e-6589103a6466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 6ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_model  = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "predictions = [pred_model.predict(batch_images)\n",
        "              for batch_images, batch_labels in batch_dataset(pool_negatives)]\n",
        "preds       = np.concatenate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c1aeb1ab",
      "metadata": {
        "id": "c1aeb1ab"
      },
      "outputs": [],
      "source": [
        "best_confidence          = preds.max(axis=1)\n",
        "budget                   = 500\n",
        "least_confidence_indexes = np.argsort(best_confidence)[:budget]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1b372a78",
      "metadata": {
        "id": "1b372a78"
      },
      "outputs": [],
      "source": [
        "images, labels = tuple(zip(*pool_negatives,*pool_positives))\n",
        "chosen_images = np.array(images)[least_confidence_indexes]\n",
        "chosen_labels = np.array(labels)[least_confidence_indexes]\n",
        "least_confidence_dataset = tf.data.Dataset.from_tensor_slices((chosen_images, chosen_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8542c89d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8542c89d",
        "outputId": "da6f6333-8131-4202-a136-9657fcec2d64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "best_confidence[least_confidence_indexes][:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f96c74d8",
      "metadata": {
        "id": "f96c74d8"
      },
      "outputs": [],
      "source": [
        "new_train_dataset = train_dataset.concatenate(least_confidence_dataset)\n",
        "new_train_dataset = batch_dataset(new_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f096d81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f096d81b",
        "outputId": "8c3cfd15-4fd7-4c69-8018-028de368b1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0414 - binary_accuracy: 0.9944 - val_loss: 7.2762 - val_binary_accuracy: 0.5238\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0216 - binary_accuracy: 0.9961 - val_loss: 7.9157 - val_binary_accuracy: 0.5208\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0352 - binary_accuracy: 0.9941 - val_loss: 8.2650 - val_binary_accuracy: 0.5214\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0248 - binary_accuracy: 0.9957 - val_loss: 8.4826 - val_binary_accuracy: 0.5152\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0280 - binary_accuracy: 0.9945 - val_loss: 7.8601 - val_binary_accuracy: 0.5224\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0216 - binary_accuracy: 0.9963 - val_loss: 8.4611 - val_binary_accuracy: 0.5182\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0510 - binary_accuracy: 0.9928 - val_loss: 8.2124 - val_binary_accuracy: 0.5190\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0588 - binary_accuracy: 0.9927 - val_loss: 8.6820 - val_binary_accuracy: 0.5140\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0473 - binary_accuracy: 0.9931 - val_loss: 8.0382 - val_binary_accuracy: 0.5244\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0461 - binary_accuracy: 0.9945 - val_loss: 8.7683 - val_binary_accuracy: 0.5130\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0485 - binary_accuracy: 0.9934 - val_loss: 8.6575 - val_binary_accuracy: 0.5274\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0359 - binary_accuracy: 0.9952 - val_loss: 8.1805 - val_binary_accuracy: 0.5342\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0570 - binary_accuracy: 0.9948 - val_loss: 8.2728 - val_binary_accuracy: 0.5308\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0330 - binary_accuracy: 0.9961 - val_loss: 9.0613 - val_binary_accuracy: 0.5236\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0353 - binary_accuracy: 0.9959 - val_loss: 8.3531 - val_binary_accuracy: 0.5342\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0334 - binary_accuracy: 0.9956 - val_loss: 8.7321 - val_binary_accuracy: 0.5280\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0256 - binary_accuracy: 0.9961 - val_loss: 8.4149 - val_binary_accuracy: 0.5324\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0234 - binary_accuracy: 0.9963 - val_loss: 9.3432 - val_binary_accuracy: 0.5212\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0175 - binary_accuracy: 0.9974 - val_loss: 10.5596 - val_binary_accuracy: 0.5054\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0530 - binary_accuracy: 0.9919 - val_loss: 9.0400 - val_binary_accuracy: 0.5230\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0764 - binary_accuracy: 0.9917 - val_loss: 7.3236 - val_binary_accuracy: 0.5440\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0185 - binary_accuracy: 0.9974 - val_loss: 8.9526 - val_binary_accuracy: 0.5236\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0186 - binary_accuracy: 0.9977 - val_loss: 8.8796 - val_binary_accuracy: 0.5286\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0189 - binary_accuracy: 0.9970 - val_loss: 9.3117 - val_binary_accuracy: 0.5180\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0989 - binary_accuracy: 0.9905 - val_loss: 8.3069 - val_binary_accuracy: 0.5448\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0139 - binary_accuracy: 0.9973 - val_loss: 9.2664 - val_binary_accuracy: 0.5266\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0136 - binary_accuracy: 0.9972 - val_loss: 10.3596 - val_binary_accuracy: 0.5150\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0071 - binary_accuracy: 0.9986 - val_loss: 9.7467 - val_binary_accuracy: 0.5224\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0069 - binary_accuracy: 0.9988 - val_loss: 9.0135 - val_binary_accuracy: 0.5382\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 3s 22ms/step - loss: 0.0260 - binary_accuracy: 0.9959 - val_loss: 8.8438 - val_binary_accuracy: 0.5356\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0224 - binary_accuracy: 0.9959 - val_loss: 8.0536 - val_binary_accuracy: 0.5526\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0187 - binary_accuracy: 0.9960 - val_loss: 8.1846 - val_binary_accuracy: 0.5476\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0142 - binary_accuracy: 0.9977 - val_loss: 8.9524 - val_binary_accuracy: 0.5354\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0091 - binary_accuracy: 0.9981 - val_loss: 8.6746 - val_binary_accuracy: 0.5388\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0064 - binary_accuracy: 0.9987 - val_loss: 9.3311 - val_binary_accuracy: 0.5294\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0071 - binary_accuracy: 0.9986 - val_loss: 9.3474 - val_binary_accuracy: 0.5306\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0024 - binary_accuracy: 0.9995 - val_loss: 10.6745 - val_binary_accuracy: 0.5222\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0056 - binary_accuracy: 0.9988 - val_loss: 10.7217 - val_binary_accuracy: 0.5288\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0035 - binary_accuracy: 0.9992 - val_loss: 10.9614 - val_binary_accuracy: 0.5294\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0055 - binary_accuracy: 0.9988 - val_loss: 11.7130 - val_binary_accuracy: 0.5144\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0097 - binary_accuracy: 0.9980 - val_loss: 11.2197 - val_binary_accuracy: 0.5190\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0048 - binary_accuracy: 0.9987 - val_loss: 12.3184 - val_binary_accuracy: 0.5078\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0468 - binary_accuracy: 0.9933 - val_loss: 9.3681 - val_binary_accuracy: 0.5498\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0057 - binary_accuracy: 0.9987 - val_loss: 11.5927 - val_binary_accuracy: 0.5220\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0069 - binary_accuracy: 0.9985 - val_loss: 10.1873 - val_binary_accuracy: 0.5420\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0034 - binary_accuracy: 0.9993 - val_loss: 11.0729 - val_binary_accuracy: 0.5292\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0105 - binary_accuracy: 0.9983 - val_loss: 9.5087 - val_binary_accuracy: 0.5520\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 3s 22ms/step - loss: 0.0201 - binary_accuracy: 0.9972 - val_loss: 9.2202 - val_binary_accuracy: 0.5490\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0075 - binary_accuracy: 0.9979 - val_loss: 9.6818 - val_binary_accuracy: 0.5454\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 11.8603 - val_binary_accuracy: 0.5278\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0043 - binary_accuracy: 0.9990 - val_loss: 11.6213 - val_binary_accuracy: 0.5408\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0091 - binary_accuracy: 0.9982 - val_loss: 12.4515 - val_binary_accuracy: 0.5212\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0099 - binary_accuracy: 0.9981 - val_loss: 12.7537 - val_binary_accuracy: 0.5154\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0148 - binary_accuracy: 0.9972 - val_loss: 9.7445 - val_binary_accuracy: 0.5574\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0035 - binary_accuracy: 0.9990 - val_loss: 9.7848 - val_binary_accuracy: 0.5614\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0331 - binary_accuracy: 0.9959 - val_loss: 10.0453 - val_binary_accuracy: 0.5566\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0318 - binary_accuracy: 0.9964 - val_loss: 13.6953 - val_binary_accuracy: 0.5142\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0099 - binary_accuracy: 0.9986 - val_loss: 10.7518 - val_binary_accuracy: 0.5528\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0068 - binary_accuracy: 0.9983 - val_loss: 10.6811 - val_binary_accuracy: 0.5462\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0065 - binary_accuracy: 0.9983 - val_loss: 11.5066 - val_binary_accuracy: 0.5322\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0052 - binary_accuracy: 0.9989 - val_loss: 12.1676 - val_binary_accuracy: 0.5274\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0079 - binary_accuracy: 0.9982 - val_loss: 10.9811 - val_binary_accuracy: 0.5418\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0052 - binary_accuracy: 0.9986 - val_loss: 12.3081 - val_binary_accuracy: 0.5340\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0016 - binary_accuracy: 0.9997 - val_loss: 11.1597 - val_binary_accuracy: 0.5574\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 3s 22ms/step - loss: 8.9418e-04 - binary_accuracy: 0.9999 - val_loss: 14.5103 - val_binary_accuracy: 0.5154\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 3s 22ms/step - loss: 0.0249 - binary_accuracy: 0.9960 - val_loss: 10.5651 - val_binary_accuracy: 0.5604\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0237 - binary_accuracy: 0.9968 - val_loss: 12.1783 - val_binary_accuracy: 0.5318\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0022 - binary_accuracy: 0.9996 - val_loss: 11.4720 - val_binary_accuracy: 0.5522\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0022 - binary_accuracy: 0.9994 - val_loss: 11.3751 - val_binary_accuracy: 0.5630\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0047 - binary_accuracy: 0.9990 - val_loss: 10.7367 - val_binary_accuracy: 0.5704\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0070 - binary_accuracy: 0.9983 - val_loss: 12.7211 - val_binary_accuracy: 0.5366\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0106 - binary_accuracy: 0.9977 - val_loss: 10.0403 - val_binary_accuracy: 0.5680\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0244 - binary_accuracy: 0.9963 - val_loss: 10.5164 - val_binary_accuracy: 0.5566\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0181 - binary_accuracy: 0.9967 - val_loss: 9.4403 - val_binary_accuracy: 0.5758\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0022 - binary_accuracy: 0.9997 - val_loss: 12.0543 - val_binary_accuracy: 0.5404\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0147 - binary_accuracy: 0.9982 - val_loss: 10.4748 - val_binary_accuracy: 0.5788\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0028 - binary_accuracy: 0.9993 - val_loss: 11.7994 - val_binary_accuracy: 0.5482\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0042 - binary_accuracy: 0.9988 - val_loss: 14.8724 - val_binary_accuracy: 0.5208\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0311 - binary_accuracy: 0.9958 - val_loss: 12.3123 - val_binary_accuracy: 0.5440\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0028 - binary_accuracy: 0.9993 - val_loss: 10.5299 - val_binary_accuracy: 0.5706\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0098 - binary_accuracy: 0.9983 - val_loss: 11.7818 - val_binary_accuracy: 0.5568\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0099 - binary_accuracy: 0.9981 - val_loss: 10.5231 - val_binary_accuracy: 0.5688\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0074 - binary_accuracy: 0.9984 - val_loss: 10.8195 - val_binary_accuracy: 0.5732\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0027 - binary_accuracy: 0.9993 - val_loss: 11.6452 - val_binary_accuracy: 0.5640\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0194 - binary_accuracy: 0.9970 - val_loss: 12.1368 - val_binary_accuracy: 0.5526\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.0036 - binary_accuracy: 0.9993 - val_loss: 11.0991 - val_binary_accuracy: 0.5548\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0034 - binary_accuracy: 0.9993 - val_loss: 12.5314 - val_binary_accuracy: 0.5496\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0042 - binary_accuracy: 0.9991 - val_loss: 13.2888 - val_binary_accuracy: 0.5356\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0054 - binary_accuracy: 0.9984 - val_loss: 11.5498 - val_binary_accuracy: 0.5438\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0198 - binary_accuracy: 0.9965 - val_loss: 12.5412 - val_binary_accuracy: 0.5388\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0188 - binary_accuracy: 0.9967 - val_loss: 13.4579 - val_binary_accuracy: 0.5298\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0066 - binary_accuracy: 0.9984 - val_loss: 12.1321 - val_binary_accuracy: 0.5442\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0057 - binary_accuracy: 0.9989 - val_loss: 11.5340 - val_binary_accuracy: 0.5604\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0064 - binary_accuracy: 0.9989 - val_loss: 12.9106 - val_binary_accuracy: 0.5490\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0100 - binary_accuracy: 0.9983 - val_loss: 14.1461 - val_binary_accuracy: 0.5280\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0095 - binary_accuracy: 0.9986 - val_loss: 12.7719 - val_binary_accuracy: 0.5416\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 12.2959 - val_binary_accuracy: 0.5560\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - val_loss: 15.2158 - val_binary_accuracy: 0.5234\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0099 - binary_accuracy: 0.9983 - val_loss: 11.2077 - val_binary_accuracy: 0.5722\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.0046 - binary_accuracy: 0.9992 - val_loss: 11.7671 - val_binary_accuracy: 0.5612\n"
          ]
        }
      ],
      "source": [
        "history2 = model.fit(new_train_dataset, \n",
        "                     validation_data=val_dataset, \n",
        "                     epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b7da6563",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "b7da6563",
        "outputId": "6ec611a8-7e82-4861-d983-79e57f88457d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epochs_plot = np.arange(1, epochs + 1)\n",
        "\n",
        "plt.plot(epochs_plot, history1.history['binary_accuracy'], label = 'Full Dataset')\n",
        "plt.plot(epochs_plot, history2.history['binary_accuracy'], label = 'Active Learning')\n",
        "plt.title('Acurácia dos modelos')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "09ab9d09769e58172906761f459bc163a0e89466ed4f026e5ecbc7e4a778c55c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}