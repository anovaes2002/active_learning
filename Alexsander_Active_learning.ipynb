{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anovaes2002/active_learning/blob/main/Alexsander_Active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b06e0c37",
      "metadata": {
        "id": "b06e0c37"
      },
      "outputs": [],
      "source": [
        "#importando bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f123a4e7",
      "metadata": {
        "id": "f123a4e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0763c9a4-b9a3-4436-ecee-4296952c9f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 50000\n"
          ]
        }
      ],
      "source": [
        "#Importando dataset imdb\n",
        "# Usaremos o conjunto de dados de avaliações do IMDB para nossos experimentos.\n",
        "# Este conjunto de dados tem 50.000 revisões no total, incluindo divisões de treinamento e teste. \n",
        "# Vamos mesclar essas divisões e amostrar nossos próprios conjuntos de treinamento, validação e teste balanceados.\n",
        "\n",
        "dataset = tfds.load(\"imdb_reviews\",\n",
        "                    split         = \"train + test\",\n",
        "                    as_supervised = True,\n",
        "                    batch_size    = -1,\n",
        "                    shuffle_files = False,)\n",
        "reviews, labels = tfds.as_numpy(dataset)\n",
        "\n",
        "print(\"Total examples:\", reviews.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definindo o tamanho do dataset\n",
        "val_split   =  2500\n",
        "test_split  =  2500\n",
        "train_split = 15000\n",
        "\n",
        "# Separando as amostras negativas e positivas para estratificação manual\n",
        "x_positives, y_positives = reviews[labels == 1], labels[labels == 1]\n",
        "x_negatives, y_negatives = reviews[labels == 0], labels[labels == 0]\n",
        "\n",
        "# Criação de divisões de treinamento, validação e teste\n",
        "x_val, y_val = (\n",
        "    tf.concat((x_positives[:val_split], x_negatives[:val_split]), 0),\n",
        "    tf.concat((y_positives[:val_split], y_negatives[:val_split]), 0),\n",
        ")\n",
        "x_test, y_test = (\n",
        "    tf.concat(\n",
        "        (\n",
        "            x_positives[val_split : val_split + test_split],\n",
        "            x_negatives[val_split : val_split + test_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        "    tf.concat(\n",
        "        (\n",
        "            y_positives[val_split : val_split + test_split],\n",
        "            y_negatives[val_split : val_split + test_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        ")\n",
        "x_train, y_train = (\n",
        "    tf.concat(\n",
        "        (\n",
        "            x_positives[val_split + test_split : val_split + test_split + train_split],\n",
        "            x_negatives[val_split + test_split : val_split + test_split + train_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        "    tf.concat(\n",
        "        (\n",
        "            y_positives[val_split + test_split : val_split + test_split + train_split],\n",
        "            y_negatives[val_split + test_split : val_split + test_split + train_split],\n",
        "        ),\n",
        "        0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# O conjunto restante de amostras é armazenado separadamente. \n",
        "# Estes são rotulados apenas como e quando necessário\n",
        "x_pool_positives, y_pool_positives = (\n",
        "    x_positives[val_split + test_split + train_split :],\n",
        "    y_positives[val_split + test_split + train_split :],\n",
        ")\n",
        "x_pool_negatives, y_pool_negatives = (\n",
        "    x_negatives[val_split + test_split + train_split :],\n",
        "    y_negatives[val_split + test_split + train_split :],\n",
        ")\n",
        "\n",
        "# Criação de conjuntos de dados para pré-busca e paralelização mais rápidas\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset   = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset  = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "pool_negatives = tf.data.Dataset.from_tensor_slices((x_pool_negatives, y_pool_negatives))\n",
        "pool_positives = tf.data.Dataset.from_tensor_slices((x_pool_positives, y_pool_positives))\n",
        "\n",
        "# Criação de Dataset Unlabel\n",
        "unlabel_dataset = (\n",
        "    pool_positives\n",
        "    .concatenate(pool_negatives)\n",
        "    .cache()\n",
        "    .shuffle(5000)\n",
        ")\n",
        "\n",
        "# Criação de Dataset FULL com somatorio de treino e pool\n",
        "full_train_dataset = (\n",
        "    train_dataset.concatenate(pool_positives)\n",
        "    .concatenate(pool_negatives)\n",
        "    .cache()\n",
        "    .shuffle(20000)\n",
        ")"
      ],
      "metadata": {
        "id": "Vi5B-AjgUFF_"
      },
      "id": "Vi5B-AjgUFF_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime tamanho dos datasets\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Testing set size: {len(test_dataset)}\")\n",
        "print(f\"Unlabeled negative pool: {len(pool_negatives)}\")\n",
        "print(f\"Unlabeled positive pool: {len(pool_positives)}\")\n",
        "print(f\"Unlabel Dataset set size: {len(unlabel_dataset)}\")\n",
        "print(f\"Full Train Dataset set size: {len(full_train_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lAPeOYyu4s6",
        "outputId": "dd376017-0bc6-4e0a-b7d5-90476e2df47e"
      },
      "id": "6lAPeOYyu4s6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 30000\n",
            "Validation set size: 5000\n",
            "Testing set size: 5000\n",
            "Unlabeled negative pool: 5000\n",
            "Unlabeled positive pool: 5000\n",
            "Unlabel Dataset set size: 10000\n",
            "Full Train Dataset set size: 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Como estamos trabalhando com dados de texto, precisaremos codificar as sequências de texto como vetores\n",
        "# que serão passados ​​por uma camada de Embedding. \n",
        "# Para tornar esse processo de tokenização mais rápido, usamos a map()função com sua funcionalidade de paralelização.\n",
        "\n",
        "# Para tratar os textos\n",
        "def custom_standardization(input_data):\n",
        "    lowercase     = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "# Vetorização dos textos\n",
        "vectorizer = layers.TextVectorization(3000, standardize=custom_standardization, output_sequence_length=150)\n",
        "\n",
        "# Adaptando o dataset\n",
        "vectorizer.adapt(train_dataset.map(lambda x, y: x, num_parallel_calls=tf.data.AUTOTUNE).batch(256))\n",
        "\n",
        "# Para vetorizar sequencia de texto\n",
        "def vectorize_text(text, label):\n",
        "    text = vectorizer(text)\n",
        "    return text, label\n",
        "\n",
        "# Para redimensionar o dataset dividindo por 100\n",
        "def batch_dataset(dataset):\n",
        "    ds = dataset.batch(100)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "JqDfO1ukUePC"
      },
      "id": "JqDfO1ukUePC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "715ccd1b",
      "metadata": {
        "id": "715ccd1b"
      },
      "outputs": [],
      "source": [
        "#Aplicando a vetorização nos datasets\n",
        "train_dataset       = train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "pool_negatives      = pool_negatives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "pool_positives      = pool_positives.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "full_train_dataset  = full_train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "unlabel_dataset     = unlabel_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#Reduzindo o tamanho dos datasets val e test\n",
        "val_dataset  = val_dataset.batch(16).map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(16).map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprime o tamanho atualizado dos datasets\n",
        "print(f\"Full Train dataset size: {len(full_train_dataset)}\")\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Testing dataset size: {len(test_dataset)}\")\n",
        "print(f\"Unlabeled negative pool size: {len(pool_negatives)}\")\n",
        "print(f\"Unlabeled positive pool size: {len(pool_positives)}\")\n",
        "print(f\"Unlabel dataset size: {len(unlabel_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTMq1PpevdQ0",
        "outputId": "b094b835-4db9-4207-a21f-27f49cb8ffb3"
      },
      "id": "kTMq1PpevdQ0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Train dataset size: 40000\n",
            "Training dataset size: 30000\n",
            "Validation dataset size: 313\n",
            "Testing dataset size: 313\n",
            "Unlabeled negative pool size: 5000\n",
            "Unlabeled positive pool size: 5000\n",
            "Unlabel dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8c32d3b6",
      "metadata": {
        "id": "8c32d3b6"
      },
      "outputs": [],
      "source": [
        "#Épocas de treinamento\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d73c14fe",
      "metadata": {
        "id": "d73c14fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1199ca9-613c-49e3-ae66-cb5977ea554b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 150, 128)          384000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 150, 64)          41216     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                1300      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 426,537\n",
            "Trainable params: 426,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Definindo o modelo\n",
        "model = keras.models.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(150,)),\n",
        "        layers.Embedding(input_dim=3000, output_dim=128),\n",
        "        layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n",
        "        layers.GlobalMaxPool1D(),\n",
        "        layers.Dense(20, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "efdfb7b4",
      "metadata": {
        "id": "efdfb7b4"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss      = \"binary_crossentropy\",\n",
        "    optimizer = \"rmsprop\",\n",
        "    metrics   = \"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e1e297ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1e297ba",
        "outputId": "3461f8f7-adea-4dc8-8a6a-043d69028808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 30s 20ms/step - loss: 0.4236 - accuracy: 0.8112 - val_loss: 0.3461 - val_accuracy: 0.8438\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.3320 - accuracy: 0.8660 - val_loss: 0.3185 - val_accuracy: 0.8654\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.3027 - accuracy: 0.8798 - val_loss: 0.3092 - val_accuracy: 0.8716\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2770 - accuracy: 0.8896 - val_loss: 0.3037 - val_accuracy: 0.8706\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2538 - accuracy: 0.9006 - val_loss: 0.3129 - val_accuracy: 0.8682\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.2316 - accuracy: 0.9109 - val_loss: 0.3101 - val_accuracy: 0.8690\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 0.2084 - accuracy: 0.9213 - val_loss: 0.3366 - val_accuracy: 0.8638\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1852 - accuracy: 0.9319 - val_loss: 0.3740 - val_accuracy: 0.8616\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1606 - accuracy: 0.9426 - val_loss: 0.4513 - val_accuracy: 0.8598\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 23s 19ms/step - loss: 0.1352 - accuracy: 0.9521 - val_loss: 0.4304 - val_accuracy: 0.8632\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1115 - accuracy: 0.9615 - val_loss: 0.4830 - val_accuracy: 0.8566\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 26s 21ms/step - loss: 0.0908 - accuracy: 0.9709 - val_loss: 0.5193 - val_accuracy: 0.8542\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.0744 - accuracy: 0.9765 - val_loss: 0.5913 - val_accuracy: 0.8512\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.0588 - accuracy: 0.9819 - val_loss: 0.6480 - val_accuracy: 0.8586\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.7076 - val_accuracy: 0.8492\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.7618 - val_accuracy: 0.8494\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 0.7843 - val_accuracy: 0.8510\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.9157 - val_accuracy: 0.8464\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 1.0694 - val_accuracy: 0.8498\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 1.2742 - val_accuracy: 0.8538\n"
          ]
        }
      ],
      "source": [
        "#Para mostrar a eficácia do Active Learning, vamos primeiro treinar o modelo em todo o conjunto de dados contendo 40000 amostras. \n",
        "#Este modelo será utilizado para comparação posteriormente.\n",
        "\n",
        "history1  = model.fit(\n",
        "    full_train_dataset.batch(32),\n",
        "    epochs          = epochs,\n",
        "    validation_data = val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5d7f025d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d7f025d",
        "outputId": "118a98ab-b070-4894-a5c1-0572c810f039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4/4 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predições\n",
        "# Carregando o modelo já treinado\n",
        "prediction_model  = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "\n",
        "# Realiza as predições do dataset unlabel\n",
        "prediction_unlabel = [prediction_model.predict(batch_unlabels)\n",
        "              for batch_unlabels, batch_labels in batch_dataset(unlabel_dataset)]\n",
        "\n",
        "# Concatena os dados retornados na linha anterior\n",
        "prediction = np.concatenate(prediction_unlabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c1aeb1ab",
      "metadata": {
        "id": "c1aeb1ab"
      },
      "outputs": [],
      "source": [
        "# Calculando a probabilidade máxima para cada amostra de acordo com o dataset não rotulado, \n",
        "# e selecionando as amostras com os menores valores até que a quantidade total em \"budget\" seja selecionada.\n",
        "\n",
        "# Melhores resultados\n",
        "bests_results = prediction.max(axis=1)\n",
        "\n",
        "# Quantidade de dados a selecionar\n",
        "target = 100\n",
        "\n",
        "# Ordenando os índices\n",
        "index_order = np.argsort(bests_results)[:target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1b372a78",
      "metadata": {
        "id": "1b372a78"
      },
      "outputs": [],
      "source": [
        "# Unindo os dados do dataset unlabel\n",
        "unlabels, labels = tuple(zip(*unlabel_dataset))\n",
        "\n",
        "# Dados escolhidos baseados nas probabilidades menores\n",
        "unlabels_small = np.array(unlabels)[index_order]\n",
        "\n",
        "# Labels escolhidos baseados nas probabilidades menores\n",
        "labels_small = np.array(labels)[index_order]\n",
        "\n",
        "# Criando a lista com seus labels\n",
        "unlabel_dataset = tf.data.Dataset.from_tensor_slices((unlabels_small, labels_small))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f96c74d8",
      "metadata": {
        "id": "f96c74d8"
      },
      "outputs": [],
      "source": [
        "# Novo dataset contendo os dados unlabel\n",
        "# Agregando ao dataset dataset de treinamento redimensionado o dataset unlabel\n",
        "new_train_dataset = train_dataset.concatenate(unlabel_dataset)\n",
        "\n",
        "# Reduzindo o novo dataset de treinamento com o batch_dataset(100)\n",
        "new_train_dataset = batch_dataset(new_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#listando o tamanho dos datasets\n",
        "print(\"Total examples:\", reviews.shape[0])\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"New Train Dataset set size: {len(new_train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Testing set size: {len(test_dataset)}\")\n",
        "print(f\"Unlabels set size: {len(unlabels)}\")\n",
        "print(f\"Labels set size: {len(labels)}\")\n",
        "print(f\"Unlabel Dataset set size: {len(unlabel_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENnadLMMwzZt",
        "outputId": "8086b19e-f8bb-40b8-eeb2-5a9d716ab3cf"
      },
      "id": "ENnadLMMwzZt",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 50000\n",
            "Training set size: 30000\n",
            "New Train Dataset set size: 301\n",
            "Validation set size: 313\n",
            "Testing set size: 313\n",
            "Unlabels set size: 10000\n",
            "Labels set size: 10000\n",
            "Unlabel Dataset set size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f096d81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f096d81b",
        "outputId": "efa2beae-6b41-4dec-da1f-5e0720ad1e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "301/301 [==============================] - 8s 27ms/step - loss: 0.0283 - accuracy: 0.9972 - val_loss: 1.7397 - val_accuracy: 0.8484\n",
            "Epoch 2/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 2.0563 - val_accuracy: 0.8472\n",
            "Epoch 3/20\n",
            "301/301 [==============================] - 8s 27ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 2.7121 - val_accuracy: 0.8132\n",
            "Epoch 4/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 2.8578 - val_accuracy: 0.8122\n",
            "Epoch 5/20\n",
            "301/301 [==============================] - 8s 28ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 5.7887 - val_accuracy: 0.7320\n",
            "Epoch 6/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 4.3617 - val_accuracy: 0.7586\n",
            "Epoch 7/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 4.3691 - val_accuracy: 0.7710\n",
            "Epoch 8/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 5.0286 - val_accuracy: 0.7516\n",
            "Epoch 9/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 7.2531 - val_accuracy: 0.6702\n",
            "Epoch 10/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0182 - accuracy: 0.9978 - val_loss: 7.0756 - val_accuracy: 0.7084\n",
            "Epoch 11/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 7.7725 - val_accuracy: 0.6640\n",
            "Epoch 12/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0238 - accuracy: 0.9986 - val_loss: 11.3794 - val_accuracy: 0.6256\n",
            "Epoch 13/20\n",
            "301/301 [==============================] - 8s 27ms/step - loss: 0.0188 - accuracy: 0.9973 - val_loss: 6.5653 - val_accuracy: 0.7238\n",
            "Epoch 14/20\n",
            "301/301 [==============================] - 8s 27ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 8.1818 - val_accuracy: 0.6814\n",
            "Epoch 15/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 12.5555 - val_accuracy: 0.6074\n",
            "Epoch 16/20\n",
            "301/301 [==============================] - 8s 27ms/step - loss: 0.0169 - accuracy: 0.9981 - val_loss: 12.1771 - val_accuracy: 0.6122\n",
            "Epoch 17/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 7.1740 - val_accuracy: 0.6966\n",
            "Epoch 18/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 10.3970 - val_accuracy: 0.6486\n",
            "Epoch 19/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 6.3149 - val_accuracy: 0.7374\n",
            "Epoch 20/20\n",
            "301/301 [==============================] - 8s 26ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 7.5158 - val_accuracy: 0.7170\n"
          ]
        }
      ],
      "source": [
        "#Treinando novamente agora com os datasets reduzidos\n",
        "history2 = model.fit(new_train_dataset, \n",
        "                     validation_data = val_dataset, \n",
        "                     epochs          = epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b7da6563",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "b7da6563",
        "outputId": "81b15cf8-18f1-4a49-f38c-1471df52b784"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xV9fnA8c+THZJAgCAjIQwFBWRHUYsIKgrujYqzjtKKtVqr0lpFat2to8PRVlGrgD8QxI2DIXVAkDBFAghkMBJCQjZJ7vP745yES8gkubkZz/v1uq97xvec+5xzzz3PPd/vGaKqGGOMMXUV4O8AjDHGtCyWOIwxxtSLJQ5jjDH1YonDGGNMvVjiMMYYUy+WOIwxxtSLJQ7ToojIQyKyU0QGi8jiRpzvdBH5b2PNz9dEJFhEkkTk/DqW/1hEbmykz14iIrc2xryagojMFJFH61h2u4ic7euYWjpLHC2YiFwrIokikiciu9ydw2h/x+VjQ4AzgWeBr/wcy2HcHep+EQltgo+bBnygqh/WpbCqTlTV130ck2kjgvwdgDk6InIP8AAwBfgUOAhMAC4GlvsxtBqJSJCqlh7t9Kp6hdvZrP4Vikhv4HQgB7gI+L9Gnr8AoqoeEQkEsoG/N+ZnGFNXdsTRAolIB2AGcIeqvquq+apaoqrvq+rv3DKhIvKciKS7r+fK/wmLyFgRSRWR+0Rkr3u0comInCcim0UkS0R+7/V500VkrojMEZFcEfleRIZ6jX9ARLa64zaKyKVe424Skf+JyLMisg+YLiLHisiXIrJPRDJF5C0RifaapqeIvCsiGW6Zv7vDa5tugPuvP1tENojIRTWswz4istSN+TMgptL4U0Tka3dea0RkbC1fyw3At8BM4LAqoRqW57DqMRHpLSIqIkFu/xIR+bOI/A8oAPqKyM3AeuDPwBYR+UWlz7rYrcI64H4nE7zmdWtd1mMV62q8iGwSkRw3dvEaFyAiD4rIDndbesPdPhGRMBH5r/s52SKyUkS6VvMZ20XkdyKyVkTyReQ/ItLVPYrOFZHPRaSjV/mL3O842122AV7jhrvbaK6IzAHCKn3WBe46yna/4yHVxFTTbyhGRD5w55ElIl+JSNvZn6qqvVrYC+fIohQIqqHMDJwd2TFAF+Br4E/uuLHu9A8BwcBtQAbwNhAFDAIKgT5u+elACXCFW/5e4Ccg2B1/JdAD54/IJCAf6O6Ou8n9rDtxjnDDgeOA8UCoG9sy4Dm3fCCwBqcqKgLnRz/aHVfTdMHAFuD3QAhOdVYucHw16+cb4K/uvMa4Zf/rjosF9gHnucs03u3vUsP63gL8ChjprquudVie6eWf6fb3BrT8ewWWADvd7yPIXcYLgWNxdt5n4CSUEW75k3GOeMa7cccCJ3jN69ba1mMVyxXjrpvy7/5u9/ssn9fP3WXvC0QC7wJvuuN+AbwPtHPXw0igfTWfsx1ne+3qxr0X+B4Y7q6zL4GH3bL9cbax8W5M97kxhLivHW6cwW7cJcCj7rTD3XmPcmO60f3sUK84zq7Db+hx4CX3M4JxjjbF3/uGJtsH+TsAex3FlwaTgd21lNkKnOfVfy6w3e0ei5MYAt3+KHeHNcqr/CrgErd7OvCt17gAYBdwejWfnQRc7HbfBOysJdZLgNVu96k4SazapFjNdKcDu4EAr/GzgOlVTBfv7vwivIa9zaHEcX/5zs9r/KfAjdXEMdrdOcW4/ZuAu2tbHuqWOGbUsg4WAHe53S8Dz1ZTbgnuzr6m9VjFuBsqffcCpHIocXwB/Mpr/PHuugjCSSpfA0Pq8F1uByZ79c8DXvTqvxNY4Hb/EXin0vaY5m7XY4B0vHbibgzlieNF3J2/1/gfgTO84ihPHDX9hmYA7wHH1bZsrfHVdg6tWpd9QEx5lUY1euD88yq3wx1WMQ9VLXO7C933PV7jC3H+QZZLKe9QVQ/OzqMHgIjc4HXonw2cyOFVPyle3bhVELNFJE1EDgD/9SrfE9ihVbSD1DJdDyDFjc17mWMrz8ctu19V8yuVLdcLuLJ8edxlGg10r2Je4PxrXaSqmW7/2xyqrqp2eeqo8ro7y62a2Ski23HaerzX3dbaZljLeqysB4d/91oppqq2syCcI4c3cRLubLeq5ykRCa4htMrbX3Xb42Gf6X7nKTjfdQ8gzY3TO6ZyvYDfVvpue3L4b6OmZSsv9zTOUc4iEdkmIg/UsFytjiWOlukboBjnn2J10nF+JOXi3WFHq2d5h1uXGweki0gv4F/AVKCzqkbj1MGL17SVb8H8mDtssKq2B67zKp8CxFeTFGuaLh3oWameOR7nn2hlu4COIhJRqWy5FJwjjmivV4SqPlF5RiISDlwFnCEiu0VkN041yVBx2oFqWp58nGqcct2qKFOx7kQkBOdf7l+AXqraG+cfv/e6O7aKeVRW03qsbBeHf/fi3U/V21kpsEeddrdHVHUgcBpwAc4RTEMd9pleMaW58ca6w7xjKpcC/LnSd9tOVWfV9jl4/YZUNVdVf6uqfXFOhrhHRM5qhGVrESxxtECqmoPTPvEPcRq124lzXv9EEXnKLTYLeFBEuohIjFu+IdcpjBSRy9wd4G9wEte3OPX2ilMdg9t4e2It84oC8oAcEYkFfuc1bgXOj/8JEYlwG1h/VofpvsOp77/PXRdjcdoDZlf+cFXdASQCj4hIiDinMF/oVeS/wIUicq6IBLoxjBWRuCqW5RKgDBgIDHNfA3BOFb6hluVJAsaISLzboDytlvUWitNGlA8gIhNx6vnL/Qe42T0qCRCRWBE5oYr51LQeK/sQGOT13f+awxPcLOBucU42iMRJSnNUtVRExolzvU0gcACnCstT+QOOwjvA+e5yBgO/xdkev8b5U1UK/NrdDi7Dafsp9y9gioiMEkeEiJwvIlFVfE61vyG3gf04N0Hl4GwDjbFsLYIljhZKVf8C3AM8iLPTTsH517/ALfIozs5xLbAOp6GxThdBVeM9nIbv/cD1wGXuP8qNOP+Av8GpWhgM/K+WeT0CjMD5wX2I06BavlxlODvx43B2Nrnu59Y23UF3uolAJvBP4AZV3VRNDNfiNJBmAQ8Db3jNKwXntObfc2jd/o6qfy83Aq+p6k5V3V3+wjlVdjLOP/ny5dmJU8U3yf2cz4A5ON/RKuCD6leZ8y8XZ8c9C+d7uBZY6DV+BXAzTkN8DrCUw/8xl6t2PVbxmZk4Jz88gVNF2o/Dv99XcaqkluGcMFGE0x4BToKZi/M9/uDG82ZNy1gXqvojzlHS33C+6wuBC1X1oLsdXIbTtpaFs669t5NEnJNB/o6zDre4ZatS02+oH/A5TgL+BvinqjbaBanNnRxeFWjMkURkOk4j4HVN/LnxOI2ajVG9YYxpJHbEYZolt9ojE+eowBjTjFjiMM3Vz3ESx+f+DsQYczirqjLGGFMvdsRhjDGmXtrETQ5jYmK0d+/e/g7DGGNalFWrVmWqapfKw9tE4ujduzeJiYn+DsMYY1oUEdlR1XCrqjLGGFMvljiMMcbUiyUOY4wx9WKJwxhjTL1Y4jDGGFMvPk0cIvKqOI+TXF/NeBGRF0RkiziPjBzhNe5GEUl2Xzd6DR8pIuvcaV6odPtkY4wxPubrI46ZOI85rc5EnLtM9gNux3k6FyLSCeeOpaNwbon8sBx63vCLOHe3LJ+upvkbY4xpZD69jkNVl4lI7xqKXAy84T6t61sRiRaR7jiPgPxMVbMAROQzYIKILMF5ZvG37vA3cJ6H8LHPFsI0T6rgKQMtc949pW63x6vbfeheQJDzkkAICDzUHxDk9NtBq3+pQkmh+yo4/F09EHmM8wpt79/vylNWfZxVDiuA0mJnWhGQAEDcZRD30Vne/QFe3V7DAgLd9/LtNdCru6rhAYeX6TYEQtpVs1BHx98XAMZy+GMoU91hNQ1PrWL4EUTkdpyjGOLj46sq4julxZC3F/L3QmE2HMx3XiX5h7orvw4blwcHC5zusoPlC1S+ZEf21zQuIBACQyAo1HkFhkJQiPte0zB3muBwCImC0CgIjYSQSOcHXNEd6YwPrOOmVFYKhfuhYF8Vr6wjhxXneiUHrwShjfjMHKkimZR3B4dBRBfnFXlMpW53hxYR0zQ7tfJk6SkFT4nzXlZac78EQLvO0C6m0Xcehyk9CHm74UA6HEiDA7uc7vy9ddvR1kVQuJtEukJUV+c9spszLKrboXERx1S/PZYUuttflvNeuB8Kvborhmc7w4tynPgOFkBZceOtr6Z0x0ro0r9RZ+nvxOEzqvoK8ApAQkJCw+/kWHrQ+RHk7YX8DMjbU6k7wx2/x9nYahMcASERzo85JNLpDo1yNvzy/pB2zg780EKVd3j1aw3jcHY0ZcVO/KVFh7rLip0EV+Amp1K3v3x4mVu+rjvooHAniYRGuQnFTTbI4YmgKLv6eYREQrtO7o6uM8T0c4YFBrs79wCvI4da/nGVl4NDRx8VO93SwxPRYa9Kw0oKnO9531bY+Y2zYzniSbhAUOUEE+PswMLaH1r3pcVe30Hx4cOOKHPw0PDyJFB+BHW0gts5cbWL8XrvXKm/y6FhIRFOMjxYALm7vBJCmpsg3CSRu8tZR5XXS3A7Z12ERDp/QILDIay7293u0LCKbu93txsgP9NJSnl7IHeP856ZDNuXOzv5I4iz/UR1cxJ6Uc6hBFFaVP36CQyB8E4Q3tHZDjv1hbAOznqoMs7qYvdahsDgQ38oVJ3fU/nvtqp39VQa5nGOoo84si6rwxG3O7xDlf+tG8TfiSONw59fHOcOS8OprvIevsQdHldFed/4+AHY+oXzo6huhxfa/tC/z2MGQt+xh/6JRh7jbIQhkYcniKBwZ+fWEpQWQ3EeHMx13otznSOi4twauvOc7gNpzr4kojNE9zyUENp1PjxBtOvs/GCDw/y9tLUrK4WCzENHlPle3eV/HnLSID3J+VOhZc50AcFOcgnyOqqr6A9zlj2sw5HDA0Ocf88BQc48AoK8+r1egcFV93tKnYSdn+n1nunsfPdsdLqr25mWx1HVH6GwDtA+Ftr3gO5DDnVH9XDe2/dwyvj6KKz86D7PTSi5u91+970oBzr2hh7DoV1H5/cY3vFQgihPEuEdnR29L+MVOfRnpoXzd+JYCEwVkdk4DeE5qrpLRD4FHvNqED8HmKaqWSJyQEROwXnG9A04j4/0jbD2cMwA6HPGoUTgnRQiuhz6V9Rale/kIjr7O5LmITDI+Scb1a32sh6Ps1MOCnWOiJojVadKtCAT8ve57xmHEkxJkbOs5YmhfSy07+78AWoOgkKdPyXRPWsvaxqNTxOHiMzCOXKIEZFUnDOlggFU9SXgI+A8nOf+FuA8Lxk3QfwJWOnOakZ5QznwK5yztcJxGsV91zA+7vc+m7VpAwICfNuu0BhE3CrGSOefuWkxyjxKdsFBsvK9XgUHycpz391hf7lyKMe0b9yjeV+fVXVNLeMVuKOaca8Cr1YxPBE4sVECNMYYHygqKWN9Wg7Je/Mo8zhtPxUtQF4Pz/NuFdKK5slDQ0s9yv5KyWFf/kH25x8ku7CE6p7DFxUaRMeIEDpFhFBYUtZ4C+byd1WVMca0aKpKSlYh3+/cz+qd+1mdks3G9AOUehrn6aqBAULHdiF0jgihY0QwA7q1p2NEMJ0iQunULphOkaF0auckiU5umdAg31aNWuIwxph6yCsuZW1KNqtTsp1EsTObffnOafPtQgIZGhfN7WP6Mjy+IwO6RxESdOhEGHFPmfdug/duji+/EUb5sIAAISo0iICA5nWtkSUOY4yphsejbMvM4/udh5LE5j25lB9MHNslgnEnHMOI+I4Mj4+mf9coApvZTt4XLHEYY9q0g6Ue0rILSckqIGV/ASlZhaTsLyA1q4BtmfnkFjnXz7QPC2JYfEcmnNiN4fEdGRYXTYd2wX6O3j8scRhjWjWPR9mTW8TOfQWk7D+UIFLdBLH7QNFhjczBgUJsdDg9O7Xj4mE9GBoXzfD4jvSNiWh2VUb+YonDGNMqHCz1sC0zjx9357J5Ty4/7s5ja0YeafsLOVh26A4IItA1KoyencI5tW9nenZq57w6Osmia/uwNlHd1BCWOIwxLUqZR9mZVXAoQezJZfPuXH7KzK84kykwQOgbE8GA7lGcM6grPTseSg6xHcN9ftZRa2eJwxjTLKkqu3KKKhLDj3ucRJG8J4/i0kNHEPGd2tG/q5Mg+neN4vhuUfSJibDk4EOWOIwxzUZW/kH+tyWT5cmZLN+SSVp2YcW4bu3D6N8tihtO7Uy/rlEc3zWKfl0jaRdiu7GmZmvcGOM3RSVlrNqxn6+SM1m+JYMN6QdQdc5gOu3YGG4f05eBPdrT/5ioNnsGU3NkicMY02RUlR925bJ8SwZfJWeycnsWRSUeggKEEfEduefs/ozuF8Pg2A4EBbaQO0i3QZY4jDE+tedAkXNEkZzB8i37yMxzHoh03DGRXH1SPKf3i2FU385EhtruqKWwb8oY0+i27M3jvaQ0Plm/m+S9eQB0jghhdL8YRh8Xw+h+MXTv0MofSdCKWeIwxjSKvQeKWLgmnQVJaaxPO0CAwCl9O3PFyDhG94thQLf2dgFdK2GJwxhz1HKLSvhk/W7eS0rn662ZeBQGx3bgwfMHcNHQHo3+HAjTPFjiMMbUy8FSD0s3Z7AgKY3PN+6huNRDfKd2TB13HBcNi+W4YyL9HaLxMUscxphaeTzKqp37WbA6jQ/X7SK7oIROESFMOqknFw+LZUR8dMUtwU3r5+tHx04AngcCgX+r6hOVxvfCecpfFyALuE5VU0VkHPCsV9ETgKtVdYGIzATOAHLccTepapIvl8OYtip5Ty4LktJ4Lymd1P2FhAUHcM7AblwyvAen9+tCsJ0y2yb5LHGISCDwD2A8kAqsFJGFqrrRq9gzwBuq+rqInAk8DlyvqouBYe58OuE8k3yR13S/U9W5vordmLYsI7eYhWvSmb86taKRe3S/Lvz2nP6cM7AbEXbabJvnyy3gZGCLqm4DEJHZwMWAd+IYCNzjdi8GFlQxnyuAj1W1wIexGtOmFZWUsWjjHuZ/n8qy5EzKPMrg2A48dMFALhzagy5Rof4O0TQjvkwcsUCKV38qMKpSmTXAZTjVWZcCUSLSWVX3eZW5Gvhrpen+LCIPAV8AD6hqceUPF5HbgdsB4uPjG7IcxrRKHo/y3U9ZzF+dykfrdpNXXEqPDmH8YkxfLhsRy3HHRPk7RNNM+fuY817g7yJyE7AMSAPKykeKSHdgMPCp1zTTgN1ACPAKcD8wo/KMVfUVdzwJCQmN89R4Y1qBLXvzmL86lQWr00nLLiQiJJDzBnfn0hGxnNKns11rYWrly8SRBvT06o9zh1VQ1XScIw5EJBK4XFWzvYpcBcxX1RKvaXa5ncUi8hpO8jHG1GBfXjHvr0ln/uo01qTmECBwer8u3DfheM4Z2I3wELsFuak7XyaOlUA/EemDkzCuBq71LiAiMUCWqnpwjiRerTSPa9zh3tN0V9Vd4pz7dwmw3kfxG9OiHSz18NnGPcxfncqSHzMo9SgDu7d3Ls4b1oNjouziPHN0fJY4VLVURKbiVDMFAq+q6gYRmQEkqupCYCzwuIgoTlXVHeXTi0hvnCOWpZVm/ZaIdAEESAKm+GoZjGmpvtm6jz++t54te/Po2j6UW0b34dIRsZzQrb2/QzOtgKi2/ur/hIQETUxM9HcYxvhcZl4xj334A++uTqNnp3AePH8gZw/oas/QNkdFRFapakLl4f5uHDfGNAKPR3l7xU6e+mQThSVlTB13HHeMO87aLoxPWOIwpoVbn5bDHxasZ01KNqf27cyfLjnR7hdlfMoShzEtVG5RCX9ZtJk3vtlOp4gQnps0jIuH9bB7Rhmfs8RhTAujqnywdhd/+mAjGXnFXDeqF/eeezwdwu2Z3KZpWOIwpgX5KTOfh95bz1fJmQyO7cC/bkhgaM9of4dl2hhLHMa0AEUlZby4ZCsvLt1KaGAAj1w0iOtO6WVnSxm/sMRhTDO3bHMGD723nu37CrhoaA8ePH+APVnP+JUlDmOaqT0HipjxwUY+XLuLvjER/PeWUYzuF+PvsIyxxGFMc1Na5uH1b3bw7GebOVjm4Z7x/fnFGX0JDbJrMkzzYInDmGbk+537eXD+ejbuOsAZ/bsw4+JB9Ooc4e+wjDmMJQ5jmoHsgoM8+ckmZq1IoVv7MF6cPIIJJ3azazJMs2SJwxg/8niUud+n8sTHm8gpLOG20/tw19n9ibTHs5pmzLZOY/zkx925PLhgHSu372dkr448esmJDOhud681zZ8lDmOaWH5xKc9/kcx/lv9E+7Agnrp8CFeMjLMn75kWwxKHMU1EVfl0w24eeX8ju3KKuPqkntw/4QQ6RoT4OzRj6sUShzFNYOe+Ah5euJ7FP2ZwQrco/n7tcEb26uTvsIw5KpY4jPGh4tIyXlm6jb8v3kJQgPDg+QO46bTeBAUG+Ds0Y46aTxOHiEwAnsd5dOy/VfWJSuN74TxnvAuQBVynqqnuuDJgnVt0p6pe5A7vA8wGOgOrgOtV9aAvl8OYo/H1lkweXLCebZn5nD+4Ow9eMIDuHcL9HZYxDeazvz0iEgj8A5gIDASuEZGBlYo9A7yhqkOAGcDjXuMKVXWY+7rIa/iTwLOqehywH7jFV8tgzNHYl1fMPXOSuPbf31GmysybT+Ifk0dY0jCthi+POE4GtqjqNgARmQ1cDGz0KjMQuMftXgwsqGmG4lwNdSZwrTvodWA68GKjRW3MUfJ4lP9blcJjH22i4GApd57pPL41LNhuFWJaF18mjlggxas/FRhVqcwa4DKc6qxLgSgR6ayq+4AwEUkESoEnVHUBTvVUtqqWes0ztqoPF5HbgdsB4uPjG2eJjKlG8p5cfj/fuSbj5N6d+POlJ9Kva5S/wzLGJ/zdOH4v8HcRuQlYBqQBZe64XqqaJiJ9gS9FZB2QU9cZq+orwCsACQkJ2qhRG+MqKinjb18m88qybUSE2jUZpm3wZeJIA3p69ce5wyqoajrOEQciEglcrqrZ7rg0932biCwBhgPzgGgRCXKPOo6YpzFNZdnmDB5csJ6dWQVcNiKWP5w3gM6Rof4Oyxif8+U5gSuBfiLSR0RCgKuBhd4FRCRGRMpjmIZzhhUi0lFEQsvLAD8DNqqq4rSFXOFOcyPwng+XwZgj7M0t4tezVnPDqysIDBDevnUUf71qmCUN02b47IhDVUtFZCrwKc7puK+q6gYRmQEkqupCYCzwuIgoTlXVHe7kA4CXRcSDk9yeUNXyRvX7gdki8iiwGviPr5bBGG8ejzJr5U6e/HgTRSUe7jqrH78ce6w1fps2R5w/8a1bQkKCJiYm+jsM04Jt2n2A37+7ju93ZnNK3078+dLBHNsl0t9hGeNTIrJKVRMqD/d347gxzVrhwTKe/yKZf3+1jaiwIP5y5VAuGxFrz8kwbZolDmOqsTw5kwfeXUvq/kKuHBnHtPMG0MluSGiMJQ5jKisqKeOJjzcx8+vt9O0SwezbT+GUvp39HZYxzYYlDmO8rE/L4TdzktiyN4+bTuvNAxNPsMZvYyqxxGEMUOZRXlq6lec+30zHdiG88fOTGdO/i7/DMqZZssRh2ryUrALueSeJldv3c/7g7jx6yYn2cCVjamCJw7RZqsrcVak88v5GBPjrVUO5dLidMWVMbSxxmDYpK/8g095dy6cb9nByn0789aqhxHVs5++wjGkRLHGYNmfxj3u5b+5asgsOMm3iCdx6el8C7aaExtSZJQ7TZhQeLOOxj37gzW930L9rJK/ffDIDe7T3d1jGtDiWOEybsCYlm7vnJLEtM59bR/fh3nOPt9NsjTlKljhMq1Za5uGfS7bywhfJdIkK5e1bR3HacTH+DsuYFs0Sh2m1duzL5+45SXy/M5uLhvbgTxefSId2wf4Oy5gWzxKHaXVUldkrU/jTBxsJDBCev3oYFw+r8gnDxpijYInDtCoZucVMe3ctn/+wl9OO7cwzVw6lR3S4v8MyplWxxGFajc827uGBeWvJLS7ljxcM5ObTetuzv43xAUscpsXLLy7lTx9sZPbKFAZ2b8+sq4fRv2uUv8MyptXy5TPHEZEJIvKjiGwRkQeqGN9LRL4QkbUiskRE4tzhw0TkGxHZ4I6b5DXNTBH5SUSS3NcwXy6Dad5W7chi4vNfMScxhV+OPZYFd/zMkoYxPuazIw4RCQT+AYwHUoGVIrLQ69nhAM8Ab6jq6yJyJvA4cD1QANygqski0gNYJSKfqmq2O93vVHWur2I3zV9JmYfnP0/mn0u20CM6nDm3n8rJfTr5Oyxj2gRfVlWdDGxR1W0AIjIbuBjwThwDgXvc7sXAAgBV3VxeQFXTRWQv0AXIxrR5W/bmcvecNaxLy+HKkXE8dOFAosLsNFtjmoovq6pigRSv/lR3mLc1wGVu96VAlIgc9qg1ETkZCAG2eg3+s1uF9ayIhDZu2Ka58niU17/ezvkvLCctu5CXrhvJ01cOtaRhTBPzaRtHHdwLnCEiq4EzgDSgrHykiHQH3gRuVlWPO3gacAJwEtAJuL+qGYvI7SKSKCKJGRkZPlwE0xR25xRx42sreHjhBk47tjOf/OZ0JpzYzd9hGdMm+bKqKg3o6dUf5w6roKrpuEccIhIJXF7ejiEi7YEPgT+o6rde0+xyO4tF5DWc5HMEVX0FeAUgISFBG2OBjH98uHYXv5+/joOlHh695EQmj4q3Z2YY40d1Shwicj4wCAgrH6aqM2qZbCXQT0T64CSMq4FrK803BshyjyamAa+6w0OA+TgN53MrTdNdVXeJs+e4BFhfl2UwLc+BohIefm8D81enMbRnNM9eNZS+XSL9HZYxbV6tiUNEXgLaAeOAfwNXACtqm05VS0VkKvApEAi8qqobRGQGkKiqC4GxwOMiosAy4A538quAMUBnEbnJHXaTqiYBb4lIF0CAJGBKHZfVtCDLkzO5b+4a9uQW85uz+zF13HEEBfq7ZtUYAyCqNdfiiMhaVR3i9R4JfKyqpzdNiA2XkJCgiYmJ/g7D1EHBwVIe/2gTb367g2O7RPCXq4YxrGe0v8Mypk0SkVWqmlB5eF2qqgrd94bPAzwAACAASURBVAL3mop9QPfGDM4YgMTtWfz2/9awM6vAnplhTDNWl8TxgYhEA08D3wOKU2VlTKMoKinj2c8288pX24jrGM6s207hlL6da5/QGOMXtSYOVf2T2zlPRD4AwlQ1x7dhmbZiXWoO97yTRPLePK4dFc/vzxtAZKjdQs2Y5qzaX6iInKmqX4rIZVWMQ1Xf9W1opjUrKfPwj8Vb+PuXW4iJDOX1n5/MGf27+DssY0wd1PTX7gzgS+DCKsYpYInDHJXNe3K5550k1qcd4LLhsTx84SB7Mp8xLUi1iUNVH3bfb266cExrVuZR/v3VNv6yaDNRYUG8dN0IJpxo51kY09LUemK8iDzmNo6X93cUkUd9G5ZpbbZn5jPp5W94/ONNjDuhC5/ePcaShjEtVF2uqJrodTtzVHU/cJ7vQjKticejvPnNdiY+/xU/7snl2UlDeem6kcRE2r0pjWmp6nL6SqCIhKpqMYCIhAP2qze1Ss8u5L65a1m+JZMx/bvw5OWD6d7Bnv9tTEtXl8TxFvCFe0NBgJuB130XkmnpVJX/S0zlTx9spEyVxy4dzDUn97QbExrTStTlOo4nRWQtcJY76E+q+qlvwzIt1Z4DRUx7dx1fbtrLqD6dePqKocR3bufvsIwxjahOV1qp6sfAxz6OxbRgqsp7Sek8vHADxaVlPHTBQG46rTcBAXaUYUxrU2XiEJFIVc1zu08B/g4cj9O2EQjkq2r7JovSNGuZecX8Yf46Pt2whxHx0Txzpd3+3JjWrLojjuvcGxo+jJM0JgMvAWcDNwD9myY809x9tG4XDy5YT15RKdMmnsCtp/cl0I4yjGnVqkwcqvqSiFyOkzBQ1R9FJFhVy4DX3Ee9TmvCOE0zsz//IA8t3MD7a9IZEteBv1w5lH5do/wdljGmCdR05fg8qHh2dwiwSUQeAzJwqqtMG/X5xj1Mm7+O7IKD/HZ8f6aMPZZge8iSMW1GXRrHr8e5UPBu9xWP8xRA08bkFJYw4/2NzPs+lRO6RfH6zSczsIc1dRnT1tSYOEQkEHhMVScDRUBtzxk3rdSSH/fywLx1ZOQVc+eZx3Hnmf0ICbKjDGPaohp/+W6bRi+3qqreRGSCiPwoIltE5IEqxvcSkS9EZK2ILBGROK9xN4pIsvu60Wv4SBFZ587zBbGrynwqr7iUae+u5abXVhIZFsS7vzyN355zvCUNY9qwulRVbQP+JyILgfzygar615omco9W/gGMB1KBlSKyUFU3ehV7BnhDVV8XkTOBx4HrRaQTzhldCTi3cF/lTrsfeBG4DfgO+AiYgF1j4hPfbN3Hvf+3hvScQn4xpi93j+9vj3I1xtQpcWx1XwFAfU6bORnYoqrbAERkNnAx4J04BgL3uN2LgQVu97nAZ6qa5U77GTBBRJYA7VX1W3f4G8AlWOJoVAdLPTz7+WZeWrqVXp3aMXfKqYzs1cnfYRljmom63HLkkaOcdyyQ4tWfCoyqVGYNcBnwPHApECUinauZNtZ9pVYx/AgicjtwO0B8fPxRLkLb81NmPnfNXs3a1ByuPqknD104kHYh9ihXY8whte4RRGQxTnXRYVT1zEb4/HuBv4vITcAyIA0oa4T5oqqvAK8AJCQkHBG/OVz5jQmnv7+B4MAAXpw8gomD7XkZxpgj1eWv5L1e3WHA5UBpHaZLA3p69ce5wyqoajrOEQciEglcrqrZIpIGjK007RJ3+rhKww+bp6m/nIISps1fy0frdnNq3878ddJQu/25MaZadamqWlVp0P9EZEUd5r0S6CcifXB27lcD13oXEJEYIEtVPThXor/qjvoUeExEOrr95wDTVDVLRA6498/6Duf2J3+rQyymGt9u28fdc5LIyC3m/gkncPsYu2WIMaZmdamq8m4VDQBGAh1qm05VS0VkKk4SCAReVdUNIjIDSFTVhThHFY+LiOJUVd3hTpslIn/CST4AM8obyoFfATOBcJxGcWsYPwolZR6e/WwzLy7dSu/OEbz7q9MYEhdd+4TGmDZPVGuu/heRn3DaOASniuonnB35ct+H1zgSEhI0MTHR32E0G9vdBvA1qTlMSnAawCNCrQHcGHM4EVmlqgmVh9elqqqPb0IyTU1V+b9VqUxfaA3gxpijV+vlvyJyh4hEe/V3FJFf+TYs09hyCkqY+vZq7pu7liFxHfj4rtMtaRhjjkpd7htxm6pml/e4V2/f5ruQTGP7bts+Jj6/jE837Oa+Ccfz1q2n0CPazpoyxhydulRsB4qIqNsY4t5K5KjuXWWaVkmZh+c+38w/lzhXgM/75WkM7WkN4MaYhqlL4vgEmCMiL7v9v8DOZGr2NqTncP+8taxPO8BVCXE8fOEgawA3xjSKuuxJ7se5dccUt38t0M1nEZkGKSop44Uvknl52TY6tgvhpetGMOFEa8swxjSeupxV5RGR74BjgauAGGCerwMz9bfipywemLeWbZn5XDkyjj+cP4DodlaraIxpXNUmDhHpD1zjvjKBOQCqOq5pQjN1lVtUwlOf/Mib3+4grmM4b95yMqf36+LvsIwxrVRNRxybgK+AC1R1C4CI3N0kUZk6+3LTHv4wfz27DxTx85/14d5z+9vdbI0xPlXTHuYynPtLLRaRT4DZOFePm2ZgX14xMz7YyHtJ6fTvGsk/J5/G8PiOtU9ojDENVG3iUNUFwAIRicB5ANNvgGNE5EVgvqouaqIYjRdV5b2kdGZ8sJHcohLuPrs/vxx7rD3K1RjTZOrSOJ4PvA287d6t9kqcM60scTSx9OxC/jB/HYt/zGB4fDRPXj6E/l3r81BGY4xpuHpVhrtXjVc8IMk0DY9Heeu7HTzx8SY8Cg9dMJAbT+tttz83xviFtaI2c1sz8nhg3lpWbt/P6f1ieOzSwfTs1M7fYRlj2jBLHM3Ya//7icc/3kR4cCDPXDmUy0fEImJHGcYY/7LE0Qx5PMpjH/3Av5f/xNkDjuHxy4bQJSrU32EZYwxgiaPZOVjq4b65a1iQlM6Np/bioQsHWVuGMaZZ8ek5nCIyQUR+FJEtIvJAFePjRWSxiKwWkbUicp47fLKIJHm9PCIyzB23xJ1n+bhjfLkMTSmvuJRbXl/JgqR0fnfu8Uy/yJKGMab58dkRh3v79X8A44FUYKWILFTVjV7FHgTeUdUXRWQg8BHQW1XfAt5y5zMYWKCqSV7TTVbVVvUs2My8Ym5+bSUbdx3gqSuGcFVCT3+HZIwxVfJlVdXJwBZV3QYgIrNxLiT0ThwKtHe7OwDpVcznGpyr1lutHfvyueHVFew5UMQr14/krAFd/R2SMcZUy5eJIxZI8epPBUZVKjMdWCQidwIRwNlVzGcSTsLx9pqIlOHcpffR8odMeROR23FuB098fPzRxN8k1qflcNNrKyj1KG/degoje9ltQ4wxzZu/71NxDTBTVeOA84A3RaQiJhEZBRSo6nqvaSar6mDgdPd1fVUzVtVXVDVBVRO6dGmed4pdnpzJpJe/ITQokLlTTrWkYYxpEXyZONIA74r6OHeYt1uAdwBU9RsgDOd5H+WuBmZ5T6Cqae57Ls6tUE5u1KibyMI16dw8cwVxHZ1Huh53jN06xBjTMvgycawE+olIHxEJwUkCCyuV2QmcBSAiA3ASR4bbH4Dz4KiK9g0RCRKRGLc7GLgAWE8L85/lP/HrWasZHt+Rd6acSrcOYf4OyRhj6sxnbRyqWioiU4FPgUDgVVXdICIzgERVXQj8FviX+5wPBW7yaq8YA6SUN667QoFP3aQRCHwO/MtXy9DYVJUnPtnEy0u3MWFQN567ehhhwYH+DssYY+pFqmhXbnUSEhI0MdG/Z++WlHm4f95a3v0+jcmj4plx8Yl2jYYxplkTkVWqmlB5uF053gTyi0v55Vvfs2xzBveM78+dZx5n95wyxrRYljh8bF9eMT+fuZJ1aTk8ftlgrjm5+Z4abIwxdWGJw4dSsgq44dUVpGcX8tJ1IzlnUDd/h2SMMQ1micOH/vjeejLzinnr1lEk9O7k73CMMaZR+PsCwFar8GAZX2/dx1UJPS1pGGNaFUscPvLdT/s4WOphTP/medW6McYcLUscPrJ0cwahQQGM6mNHG8aY1sUSh48s25zBqL6d7QI/Y0yrY4nDB1L3F7A1I58x/WJqL2yMMS2MJQ4fWLY5E4Cxx1v7hjGm9bHE4QPLNmfQo0MYx3aJ9HcoxhjT6CxxNLKSMg//25LJGcd3sduKGGNaJUscjSwpJZvc4lLG9LNqKmNM62SJo5Et/TGDwADhtOOsYdwY0zpZ4mhky5IzGN4zmg7hwf4OxRhjfMISRyPal1fMurQcu1rcGNOqWeJoRMu3ZKIKZ1jiMMa0Yj5NHCIyQUR+FJEtIvJAFePjRWSxiKwWkbUicp47vLeIFIpIkvt6yWuakSKyzp3nC9KMTl1aujmDju2COTG2g79DMcYYn/FZ4hCRQOAfwERgIHCNiAysVOxB4B1VHQ5cDfzTa9xWVR3mvqZ4DX8RuA3o574m+GoZ6sPjUZZtzmR0vy72SFhjTKvmyyOOk4EtqrpNVQ8Cs4GLK5VRoL3b3QFIr2mGItIdaK+q36rzsPQ3gEsaN+yj88PuA2TmFVs1lTGm1fNl4ogFUrz6U91h3qYD14lIKvARcKfXuD5uFdZSETnda56ptcwTABG5XUQSRSQxIyOjAYtRN+W3GbH7UxljWjt/N45fA8xU1TjgPOBNEQkAdgHxbhXWPcDbItK+hvkcQVVfUdUEVU3o0sX3RwFLN+9lQPf2HNM+zOefZYwx/uTLxJEG9PTqj3OHebsFeAdAVb8BwoAYVS1W1X3u8FXAVqC/O31cLfNscvnFpazasZ8x/e1owxjT+vkycawE+olIHxEJwWn8XlipzE7gLAARGYCTODJEpIvbuI6I9MVpBN+mqruAAyJyins21Q3Aez5chjr5Zus+SsqUM+w2I8aYNiDIVzNW1VIRmQp8CgQCr6rqBhGZASSq6kLgt8C/RORunIbym1RVRWQMMENESgAPMEVVs9xZ/wqYCYQDH7svv1q6OYN2IYGM7N3R36EYY4zP+SxxAKjqRziN3t7DHvLq3gj8rIrp5gHzqplnInBi40baMMuSMzi1b2dCg+xpf8aY1s/fjeMt3vbMfHbsK+AMe2iTMaaNsMTRQMuSnVN97Tbqxpi2whJHAy3bnEF8p3b0jonwdyjGGNMkLHE0wMFSD19v3WdXixtj2hRLHA2QuCOLgoNldht1Y0ybYomjAZZuziA4UDj12M7+DsUYY5qMJY4GWLY5k5G9OhIZ6tOzmo0xplmxPd5R2nugiB92HeD+CSf4OxRj/KqkpITU1FSKior8HYo5SmFhYcTFxREcXLdHXlviOErLkt274dr9qUwbl5qaSlRUFL1796YZPVfN1JGqsm/fPlJTU+nTp0+dprGqqqO0bHMGMZGhDOhWr5v2GtPqFBUV0blzZ0saLZSI0Llz53odMVriOAplHuWr5AzG9I8hwJ72Z4wljRauvt+fJY6jsD4th/0FJXb9hjGmTbLEcRSWbc5ABEYfZ+0bxjQHgYGBDBs2rOK1ffv2asvOnDmTqVOnAjB9+nSeeeaZI8pMnz6d2NhYhg0bRr9+/bjsssvYuHFjrXHMnDmT9PQan4Bdb0lJSXz00Ue1F2xCljiOwtLNGQyO7UDnyFB/h2KMAcLDw0lKSqp49e7du8HzvPvuu0lKSiI5OZlJkyZx5plnUttjqNtK4rCzqurpQFEJq1Oy+eUZx/o7FGOanUfe38DG9AONOs+BPdrz8IWD6j1d7969SUxMJCYmhsTERO69916WLFlyVDFMmjSJDz/8kLfffpu77rqLGTNm8P7771NYWMhpp53Gyy+/zLx580hMTGTy5MmEh4fzzTff8PTTTx9RTkR44YUXeOmllwgKCmLgwIHMnj2b/Px87rzzTtavX09JSQnTp09n4sSJPPTQQxQWFrJ8+XKmTZvGpEmTjmoZGpMdcdTT11syKfOo3UbdmGaksLCwoprq0ksv9clnjBgxgk2bNgEwdepUVq5cyfr16yksLOSDDz7giiuuICEhgbfeeoukpCTCw8OrLAfwxBNPsHr1atauXctLL70EwJ///GfOPPNMVqxYweLFi/nd735HSUkJM2bMYNKkSSQlJTWLpAF2xFFvSzdnEBUaxLCe0f4OxZhm52iODBpDeVWVL6lqRffixYt56qmnKCgoICsri0GDBnHhhRceMU115YYMGcLkyZO55JJLuOSSSwBYtGgRCxcurGhzKSoqYufOnT5dpqPl0yMOEZkgIj+KyBYReaCK8fEislhEVovIWhE5zx0+XkRWicg69/1Mr2mWuPNMcl/H+HIZvKkqyzZn8rPjYggOtIM1Y5qzoKAgPB4PQKNc1b569WoGDBhAUVERv/rVr5g7dy7r1q3jtttuq3L+NZX78MMPueOOO/j+++856aSTKC0tRVWZN29eRTvNzp07GTBgQIPj9gWf7f1EJBD4BzARGAhcIyIDKxV7EHhHVYcDVwP/dIdnAheq6mDgRuDNStNNVtVh7muvr5ahsq0ZeaRlF9rdcI1pAXr37s2qVasAmDevyidR19m8efNYtGgR11xzTcXOPyYmhry8PObOnVtRLioqitzcXIBqy3k8HlJSUhg3bhxPPvkkOTk55OXlce655/K3v/2t4shm9erVR8yzufDl3+aTgS2quk1VDwKzgYsrlVGg/NLrDkA6gKquVtXyUxM2AOEi4vdTmJZuttuMGNNSPPzww9x1110kJCQQGBhY7+mfffbZitNx//vf//Lll1/SpUsXoqOjue222zjxxBM599xzOemkkyqmuemmm5gyZQrDhg0jNDS0ynJlZWVcd911DB48mOHDh/PrX/+a6Oho/vjHP1JSUsKQIUMYNGgQf/zjHwEYN24cGzduZNiwYcyZM6dxVk4DiXe9XaPOWOQKYIKq3ur2Xw+MUtWpXmW6A4uAjkAEcLaqrqpiPlNU9Wy3fwnQGSgD5gGPahULISK3A7cDxMfHj9yxY0eDl+nGV1eQur+AL347tsHzMqa1+OGHH5ptlYqpu6q+RxFZpaoJlcv6u6L+GmCmqsYB5wFvikhFTCIyCHgS+IXXNJPdKqzT3df1Vc1YVV9R1QRVTejSpeFVS0UlZXy7bZ9VUxlj2jxfJo40oKdXf5w7zNstwDsAqvoNEAbEAIhIHDAfuEFVt5ZPoKpp7nsu8DZOlZjPrfgpi+JSj91mxBjT5vkycawE+olIHxEJwWn8XlipzE7gLAARGYCTODJEJBr4EHhAVf9XXlhEgkSkPLEEAxcA6324DBWWbs4gJCiAUX3saX/GmLbNZ4lDVUuBqcCnwA84Z09tEJEZInKRW+y3wG0isgaYBdzktldMBY4DHqp02m0o8KmIrAWScI5g/uWrZfC2bHMGo/p0Ijyk/o1sxhjTmvj0AkBV/Qj4qNKwh7y6NwI/q2K6R4FHq5ntyMaMsS7SswtJ3pvHpJN61l7YGGNaOX83jrcIyzY7NzazhnFjjLHEUSfLkjPo3iGMfsdE+jsUY0w1FixYgIhU3E+qJs899xwFBQUV/eeddx7Z2dkNjqF3795kZmY2eD511Vhx15cljlqUlnn4KjmTMf262FPOjGnGZs2axejRo5k1a1atZSsnjo8++ojo6OZ3/7nS0tIax/srbrvJYS3WpGaTW1Rq1VTG1MXHD8DudY07z26DYeITNRbJy8tj+fLlLF68mAsvvJBHHnkEcK7Svv/++/nkk08ICAjgtttuQ1VJT09n3LhxxMTEsHjx4opbsD/zzDP07NmTO+64A3Ae6BQZGcm9997L008/zTvvvENxcTGXXnppxWfUJiMjgylTplTcsPC5557jZz/7GStWrOCuu+6iqKiI8PBwXnvtNY4//nhmzpzJu+++S15eHmVlZdx8880sXLiQgoICtm7dyqWXXspTTz0FHLp1fF5eHhMnTmT06NF8/fXXxMbG8t577xEeHs7KlSu55ZZbCAgIYPz48Xz88cesX9+wk1HtiKMWSzdnEmBP+zOmWXvvvfeYMGEC/fv3p3PnzhX3qHrllVfYvn07SUlJrF27lsmTJ/PrX/+aHj16sHjxYhYvXnzYfCZNmsQ777xT0f/OO+8wadIkFi1aRHJyMitWrCApKYlVq1axbNmyOsV21113cffdd7Ny5UrmzZvHrbfeCsAJJ5zAV199xerVq5kxYwa///3vK6b5/vvvmTt3LkuXLgWchznNmTOHdevWMWfOHFJSUo74nOTkZO644w42bNhAdHR0xf25br75Zl5++WWSkpKO6tYrVbEjjlos3ZzBsJ7RdGgX7O9QjGn+ajky8JVZs2Zx1113AXD11Vcza9YsRo4cyeeff86UKVMICnJ2dZ06dapxPsOHD2fv3r2kp6eTkZFBx44d6dmzJ88//zyLFi1i+PDhgHOEk5yczJgxY2qN7fPPPz/ssbMHDhwgLy+PnJwcbrzxRpKTkxERSkpKKsqMHz/+sFjPOussOnToAMDAgQPZsWMHPXsefpZnnz59GDZsGAAjR45k+/btZGdnk5uby6mnngrAtddeW/FMkIawxFGD/fkHWZuazW/O6u/vUIwx1cjKyuLLL79k3bp1iAhlZWWICE8//fRRze/KK69k7ty57N69u+LBSarKtGnT+MUvflHL1EfyeDx8++23hIWFHTZ86tSpjBs3jvnz57N9+3bGjh1bMS4iIuKwsqGhh+7xGhgYWGXbR+UyhYWF9Y61rqyqqgbLt2SianfDNaY5mzt3Ltdffz07duxg+/btpKSk0KdPH7766ivGjx/Pyy+/XLGjzcrKAmq+VfmkSZOYPXs2c+fO5corrwTg3HPP5dVXXyUvLw+AtLQ09u6t2xMdzjnnHP72t79V9Jc/cConJ4fY2FjAeVa5L0RHRxMVFcV3330HwOzZsxtlvpY4arB0cwbR7YIZEtf8zrYwxjhmzZp1xONiL7/8cmbNmsWtt95KfHw8Q4YMYejQobz99tsA3H777UyYMIFx48YdMb9BgwaRm5tLbGws3bt3B5yd/7XXXsupp57K4MGDueKKK6pNPEOGDCEuLo64uDjuueceXnjhBRITExkyZAgDBw6seFTsfffdx7Rp0xg+fHitZ081xH/+8x9uu+02hg0bRn5+fkWVV0P47LbqzUlCQoImJibWe7oXl2zlQFEJ9084wQdRGdM62G3Vm7e8vDwiI51r0J544gl27drF888/f0S5+txW3do4avDLscf6OwRjjGmQDz/8kMcff5zS0lJ69erVKNViljiMMaYVmzRpUkUjf2OxNg5jTIO1hSrv1qy+358lDmNMg4SFhbFv3z5LHi2UqrJv374jTheuiVVVGWMaJC4ujtTUVDIyMvwdijlKYWFhxMXF1bm8JQ5jTIMEBwfTp08ff4dhmpBVVRljjKkXSxzGGGPqxRKHMcaYemkTV46LSAaww99xVCMGaLpHhtWfxdcwFl/DWHwN09D4eqnqEQ8jahOJozkTkcSqLulvLiy+hrH4GsbiaxhfxWdVVcYYY+rFEocxxph6scThf6/4O4BaWHwNY/E1jMXXMD6Jz9o4jDHG1IsdcRhjjKkXSxzGGGPqxRJHExCRniKyWEQ2isgGEbmrijJjRSRHRJLc10NNHON2EVnnfvYRj0sUxwsiskVE1orIiCaM7Xiv9ZIkIgdE5DeVyjTp+hORV0Vkr4is9xrWSUQ+E5Fk971jNdPe6JZJFpEbmzC+p0Vkk/v9zReRKp+JXNu24MP4potImtd3eF41004QkR/dbfGBJoxvjlds20UkqZppm2L9VblPabJtUFXt5eMX0B0Y4XZHAZuBgZXKjAU+8GOM24GYGsafB3wMCHAK8J2f4gwEduNcmOS39QeMAUYA672GPQU84HY/ADxZxXSdgG3ue0e3u2MTxXcOEOR2P1lVfHXZFnwY33Tg3jp8/1uBvkAIsKbyb8lX8VUa/xfgIT+uvyr3KU21DdoRRxNQ1V2q+r3bnQv8AMT6N6p6uxh4Qx3fAtEi0t0PcZwFbFVVv94JQFWXAVmVBl8MvO52vw5cUsWk5wKfqWqWqu4HPgMmNEV8qrpIVUvd3m+But9Hu5FVs/7q4mRgi6puU9WDwGyc9d6oaopPRAS4CpjV2J9bVzXsU5pkG7TE0cREpDcwHPiuitGnisgaEflYRAY1aWCgwCIRWSUit1cxPhZI8epPxT/J72qq/8H6c/0BdFXVXW73bqBrFWWay3r8Oc4RZFVq2xZ8aapblfZqNdUszWH9nQ7sUdXkasY36fqrtE9pkm3QEkcTEpFIYB7wG1U9UGn09zjVL0OBvwELmji80ao6ApgI3CEiY5r482slIiHARcD/VTHa3+vvMOrUCTTLc91F5A9AKfBWNUX8tS28CBwLDAN24VQHNUfXUPPRRpOtv5r2Kb7cBi1xNBERCcb5gt9S1Xcrj1fVA6qa53Z/BASLSExTxaeqae77XmA+TpWAtzSgp1d/nDusKU0EvlfVPZVH+Hv9ufaUV9+573urKOPX9SgiNwEXAJPdHcsR6rAt+ISq7lHVMlX1AP+q5nP9vf6CgMuAOdWVaar1V80+pUm2QUscTcCtE/0P8IOq/rWaMt3ccojIyTjfzb4mii9CRKLKu3EaUddXKrYQuME9u+oUIMfrkLipVPtPz5/rz8tCoPwMlRuB96oo8ylwjoh0dKtiznGH+ZyITADuAy5S1YJqytRlW/BVfN5tZpdW87krgX4i0sc9Ar0aZ703lbOBTaqaWtXIplp/NexTmmYb9GXLv70qzmIYjXPIuBZIcl/nAVOAKW6ZqcAGnLNEvgVOa8L4+rqfu8aN4Q/ucO/4BPgHzhkt64CEJl6HETiJoIPXML+tP5wEtgsowakjvgXoDHwBJAOfA53csgnAv72m/TmwxX3d3ITxbcGp2y7fBl9yy/YAPqppgdsGCwAAApNJREFUW2ii+N50t621ODvA7pXjc/vPwzmLaGtTxucOn1m+zXmV9cf6q26f0iTboN1yxBhjTL1YVZUxxph6scRhjDGmXixxGGOMqRdLHMYYY+rFEocxxph6scRh/r+9OwixKQzDOP5/jIUpNcrULIgpFhakZIGVbKytJGUxO0s7ymJ2ZKWxk2J2LKZsaFIjk6IQKRZKkg01k0lJTZoei++7mia3nM7ce5PnV7d7OrdO31m997zfve8TLUnaIGlW0o5BryWiH/Jz3IiWJO0CttueH/RaIvohhSOiBUkrlD+tddy2fXlQ64nohxSOiBYkfbe9edDriOin7HFE9EBNgbtSk+CeSdpdz49LelhHh8919kUkjamk8r2uryP1/N06nvttZ0S3pCFJtyS9qdc/N7g7jf/RxkEvIOIfN7wmQvSS7c7k1G+290k6A1ylTKW9BkzbnpY0AUxRwnamgHnbJyQNAZ2nmAnbXyUNA88lzQDjwDbbewHUJQI2olfSqopooVurStJH4JjtD3X89RfbWyUtUob3/aznP9selbRA2WBfXnOdScqkWCgF4zjwDngB3AfuAQ9cRpFH9EVaVRG94y7Hf0XSUcoY78MuAVWvgE0ucZ/7gUeUCcE3Wq80ooEUjojeObnq/Wk9fkLJkAA4DTyux3PAWfi9hzECjABLtn9I2gMcqp+PAhtszwAXgQO9vpGI1dKqimjhDz/HnbV9vraq7lBSC5eBU7bfS9oJ3ARGgQVKFsInSWPAdUqewwqliLykROCOU9pTW4BJYKleo/PF74LtbvnhEesuhSOiB2rhOGh7cdBriVhvaVVFREQjeeKIiIhG8sQRERGNpHBEREQjKRwREdFICkdERDSSwhEREY38AuDGn5SSWAyrAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Plotando as acurácias dos dois modelos\n",
        "epochs_plot = np.arange(1, epochs + 1)\n",
        "plt.plot(epochs_plot, history1.history['accuracy'], label = 'Full Dataset')\n",
        "plt.plot(epochs_plot, history2.history['accuracy'], label = 'Active Learning')\n",
        "plt.title('Comparação de Acurácia dos modelos')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "09ab9d09769e58172906761f459bc163a0e89466ed4f026e5ecbc7e4a778c55c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}